{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "43e5d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt','r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0ebc6c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e689e84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e49b0108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "81db102b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3ab59ca9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b={}\n",
    "for w in words:\n",
    "    chs=['<S>']+list(w)+['<E>']\n",
    "    for ch1, ch2 in zip(chs,chs[1:]):\n",
    "        bigram=(ch1,ch2)\n",
    "        b[bigram]= b.get(bigram,0)+1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2152254e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('n', '<E>'), 6763),\n",
       " (('a', '<E>'), 6640),\n",
       " (('a', 'n'), 5438),\n",
       " (('<S>', 'a'), 4410),\n",
       " (('e', '<E>'), 3983),\n",
       " (('a', 'r'), 3264),\n",
       " (('e', 'l'), 3248),\n",
       " (('r', 'i'), 3033),\n",
       " (('n', 'a'), 2977),\n",
       " (('<S>', 'k'), 2963),\n",
       " (('l', 'e'), 2921),\n",
       " (('e', 'n'), 2675),\n",
       " (('l', 'a'), 2623),\n",
       " (('m', 'a'), 2590),\n",
       " (('<S>', 'm'), 2538),\n",
       " (('a', 'l'), 2528),\n",
       " (('i', '<E>'), 2489),\n",
       " (('l', 'i'), 2480),\n",
       " (('i', 'a'), 2445),\n",
       " (('<S>', 'j'), 2422),\n",
       " (('o', 'n'), 2411),\n",
       " (('h', '<E>'), 2409),\n",
       " (('r', 'a'), 2356),\n",
       " (('a', 'h'), 2332),\n",
       " (('h', 'a'), 2244),\n",
       " (('y', 'a'), 2143),\n",
       " (('i', 'n'), 2126),\n",
       " (('<S>', 's'), 2055),\n",
       " (('a', 'y'), 2050),\n",
       " (('y', '<E>'), 2007),\n",
       " (('e', 'r'), 1958),\n",
       " (('n', 'n'), 1906),\n",
       " (('y', 'n'), 1826),\n",
       " (('k', 'a'), 1731),\n",
       " (('n', 'i'), 1725),\n",
       " (('r', 'e'), 1697),\n",
       " (('<S>', 'd'), 1690),\n",
       " (('i', 'e'), 1653),\n",
       " (('a', 'i'), 1650),\n",
       " (('<S>', 'r'), 1639),\n",
       " (('a', 'm'), 1634),\n",
       " (('l', 'y'), 1588),\n",
       " (('<S>', 'l'), 1572),\n",
       " (('<S>', 'c'), 1542),\n",
       " (('<S>', 'e'), 1531),\n",
       " (('j', 'a'), 1473),\n",
       " (('r', '<E>'), 1377),\n",
       " (('n', 'e'), 1359),\n",
       " (('l', 'l'), 1345),\n",
       " (('i', 'l'), 1345),\n",
       " (('i', 's'), 1316),\n",
       " (('l', '<E>'), 1314),\n",
       " (('<S>', 't'), 1308),\n",
       " (('<S>', 'b'), 1306),\n",
       " (('d', 'a'), 1303),\n",
       " (('s', 'h'), 1285),\n",
       " (('d', 'e'), 1283),\n",
       " (('e', 'e'), 1271),\n",
       " (('m', 'i'), 1256),\n",
       " (('s', 'a'), 1201),\n",
       " (('s', '<E>'), 1169),\n",
       " (('<S>', 'n'), 1146),\n",
       " (('a', 's'), 1118),\n",
       " (('y', 'l'), 1104),\n",
       " (('e', 'y'), 1070),\n",
       " (('o', 'r'), 1059),\n",
       " (('a', 'd'), 1042),\n",
       " (('t', 'a'), 1027),\n",
       " (('<S>', 'z'), 929),\n",
       " (('v', 'i'), 911),\n",
       " (('k', 'e'), 895),\n",
       " (('s', 'e'), 884),\n",
       " (('<S>', 'h'), 874),\n",
       " (('r', 'o'), 869),\n",
       " (('e', 's'), 861),\n",
       " (('z', 'a'), 860),\n",
       " (('o', '<E>'), 855),\n",
       " (('i', 'r'), 849),\n",
       " (('b', 'r'), 842),\n",
       " (('a', 'v'), 834),\n",
       " (('m', 'e'), 818),\n",
       " (('e', 'i'), 818),\n",
       " (('c', 'a'), 815),\n",
       " (('i', 'y'), 779),\n",
       " (('r', 'y'), 773),\n",
       " (('e', 'm'), 769),\n",
       " (('s', 't'), 765),\n",
       " (('h', 'i'), 729),\n",
       " (('t', 'e'), 716),\n",
       " (('n', 'd'), 704),\n",
       " (('l', 'o'), 692),\n",
       " (('a', 'e'), 692),\n",
       " (('a', 't'), 687),\n",
       " (('s', 'i'), 684),\n",
       " (('e', 'a'), 679),\n",
       " (('d', 'i'), 674),\n",
       " (('h', 'e'), 674),\n",
       " (('<S>', 'g'), 669),\n",
       " (('t', 'o'), 667),\n",
       " (('c', 'h'), 664),\n",
       " (('b', 'e'), 655),\n",
       " (('t', 'h'), 647),\n",
       " (('v', 'a'), 642),\n",
       " (('o', 'l'), 619),\n",
       " (('<S>', 'i'), 591),\n",
       " (('i', 'o'), 588),\n",
       " (('e', 't'), 580),\n",
       " (('v', 'e'), 568),\n",
       " (('a', 'k'), 568),\n",
       " (('a', 'a'), 556),\n",
       " (('c', 'e'), 551),\n",
       " (('a', 'b'), 541),\n",
       " (('i', 't'), 541),\n",
       " (('<S>', 'y'), 535),\n",
       " (('t', 'i'), 532),\n",
       " (('s', 'o'), 531),\n",
       " (('m', '<E>'), 516),\n",
       " (('d', '<E>'), 516),\n",
       " (('<S>', 'p'), 515),\n",
       " (('i', 'c'), 509),\n",
       " (('k', 'i'), 509),\n",
       " (('o', 's'), 504),\n",
       " (('n', 'o'), 496),\n",
       " (('t', '<E>'), 483),\n",
       " (('j', 'o'), 479),\n",
       " (('u', 's'), 474),\n",
       " (('a', 'c'), 470),\n",
       " (('n', 'y'), 465),\n",
       " (('e', 'v'), 463),\n",
       " (('s', 's'), 461),\n",
       " (('m', 'o'), 452),\n",
       " (('i', 'k'), 445),\n",
       " (('n', 't'), 443),\n",
       " (('i', 'd'), 440),\n",
       " (('j', 'e'), 440),\n",
       " (('a', 'z'), 435),\n",
       " (('i', 'g'), 428),\n",
       " (('i', 'm'), 427),\n",
       " (('r', 'r'), 425),\n",
       " (('d', 'r'), 424),\n",
       " (('<S>', 'f'), 417),\n",
       " (('u', 'r'), 414),\n",
       " (('r', 'l'), 413),\n",
       " (('y', 's'), 401),\n",
       " (('<S>', 'o'), 394),\n",
       " (('e', 'd'), 384),\n",
       " (('a', 'u'), 381),\n",
       " (('c', 'o'), 380),\n",
       " (('k', 'y'), 379),\n",
       " (('d', 'o'), 378),\n",
       " (('<S>', 'v'), 376),\n",
       " (('t', 't'), 374),\n",
       " (('z', 'e'), 373),\n",
       " (('z', 'i'), 364),\n",
       " (('k', '<E>'), 363),\n",
       " (('g', 'h'), 360),\n",
       " (('t', 'r'), 352),\n",
       " (('k', 'o'), 344),\n",
       " (('t', 'y'), 341),\n",
       " (('g', 'e'), 334),\n",
       " (('g', 'a'), 330),\n",
       " (('l', 'u'), 324),\n",
       " (('b', 'a'), 321),\n",
       " (('d', 'y'), 317),\n",
       " (('c', 'k'), 316),\n",
       " (('<S>', 'w'), 307),\n",
       " (('k', 'h'), 307),\n",
       " (('u', 'l'), 301),\n",
       " (('y', 'e'), 301),\n",
       " (('y', 'r'), 291),\n",
       " (('m', 'y'), 287),\n",
       " (('h', 'o'), 287),\n",
       " (('w', 'a'), 280),\n",
       " (('s', 'l'), 279),\n",
       " (('n', 's'), 278),\n",
       " (('i', 'z'), 277),\n",
       " (('u', 'n'), 275),\n",
       " (('o', 'u'), 275),\n",
       " (('n', 'g'), 273),\n",
       " (('y', 'd'), 272),\n",
       " (('c', 'i'), 271),\n",
       " (('y', 'o'), 271),\n",
       " (('i', 'v'), 269),\n",
       " (('e', 'o'), 269),\n",
       " (('o', 'm'), 261),\n",
       " (('r', 'u'), 252),\n",
       " (('f', 'a'), 242),\n",
       " (('b', 'i'), 217),\n",
       " (('s', 'y'), 215),\n",
       " (('n', 'c'), 213),\n",
       " (('h', 'y'), 213),\n",
       " (('p', 'a'), 209),\n",
       " (('r', 't'), 208),\n",
       " (('q', 'u'), 206),\n",
       " (('p', 'h'), 204),\n",
       " (('h', 'r'), 204),\n",
       " (('j', 'u'), 202),\n",
       " (('g', 'r'), 201),\n",
       " (('p', 'e'), 197),\n",
       " (('n', 'l'), 195),\n",
       " (('y', 'i'), 192),\n",
       " (('g', 'i'), 190),\n",
       " (('o', 'd'), 190),\n",
       " (('r', 's'), 190),\n",
       " (('r', 'd'), 187),\n",
       " (('h', 'l'), 185),\n",
       " (('s', 'u'), 185),\n",
       " (('a', 'x'), 182),\n",
       " (('e', 'z'), 181),\n",
       " (('e', 'k'), 178),\n",
       " (('o', 'v'), 176),\n",
       " (('a', 'j'), 175),\n",
       " (('o', 'h'), 171),\n",
       " (('u', 'e'), 169),\n",
       " (('m', 'm'), 168),\n",
       " (('a', 'g'), 168),\n",
       " (('h', 'u'), 166),\n",
       " (('x', '<E>'), 164),\n",
       " (('u', 'a'), 163),\n",
       " (('r', 'm'), 162),\n",
       " (('a', 'w'), 161),\n",
       " (('f', 'i'), 160),\n",
       " (('z', '<E>'), 160),\n",
       " (('u', '<E>'), 155),\n",
       " (('u', 'm'), 154),\n",
       " (('e', 'c'), 153),\n",
       " (('v', 'o'), 153),\n",
       " (('e', 'h'), 152),\n",
       " (('p', 'r'), 151),\n",
       " (('d', 'd'), 149),\n",
       " (('o', 'a'), 149),\n",
       " (('w', 'e'), 149),\n",
       " (('w', 'i'), 148),\n",
       " (('y', 'm'), 148),\n",
       " (('z', 'y'), 147),\n",
       " (('n', 'z'), 145),\n",
       " (('y', 'u'), 141),\n",
       " (('r', 'n'), 140),\n",
       " (('o', 'b'), 140),\n",
       " (('k', 'l'), 139),\n",
       " (('m', 'u'), 139),\n",
       " (('l', 'd'), 138),\n",
       " (('h', 'n'), 138),\n",
       " (('u', 'd'), 136),\n",
       " (('<S>', 'x'), 134),\n",
       " (('t', 'l'), 134),\n",
       " (('a', 'f'), 134),\n",
       " (('o', 'e'), 132),\n",
       " (('e', 'x'), 132),\n",
       " (('e', 'g'), 125),\n",
       " (('f', 'e'), 123),\n",
       " (('z', 'l'), 123),\n",
       " (('u', 'i'), 121),\n",
       " (('v', 'y'), 121),\n",
       " (('e', 'b'), 121),\n",
       " (('r', 'h'), 121),\n",
       " (('j', 'i'), 119),\n",
       " (('o', 't'), 118),\n",
       " (('d', 'h'), 118),\n",
       " (('h', 'm'), 117),\n",
       " (('c', 'l'), 116),\n",
       " (('o', 'o'), 115),\n",
       " (('y', 'c'), 115),\n",
       " (('o', 'w'), 114),\n",
       " (('o', 'c'), 114),\n",
       " (('f', 'r'), 114),\n",
       " (('b', '<E>'), 114),\n",
       " (('m', 'b'), 112),\n",
       " (('z', 'o'), 110),\n",
       " (('i', 'b'), 110),\n",
       " (('i', 'u'), 109),\n",
       " (('k', 'r'), 109),\n",
       " (('g', '<E>'), 108),\n",
       " (('y', 'v'), 106),\n",
       " (('t', 'z'), 105),\n",
       " (('b', 'o'), 105),\n",
       " (('c', 'y'), 104),\n",
       " (('y', 't'), 104),\n",
       " (('u', 'b'), 103),\n",
       " (('u', 'c'), 103),\n",
       " (('x', 'a'), 103),\n",
       " (('b', 'l'), 103),\n",
       " (('o', 'y'), 103),\n",
       " (('x', 'i'), 102),\n",
       " (('i', 'f'), 101),\n",
       " (('r', 'c'), 99),\n",
       " (('c', '<E>'), 97),\n",
       " (('m', 'r'), 97),\n",
       " (('n', 'u'), 96),\n",
       " (('o', 'p'), 95),\n",
       " (('i', 'h'), 95),\n",
       " (('k', 's'), 95),\n",
       " (('l', 's'), 94),\n",
       " (('u', 'k'), 93),\n",
       " (('<S>', 'q'), 92),\n",
       " (('d', 'u'), 92),\n",
       " (('s', 'm'), 90),\n",
       " (('r', 'k'), 90),\n",
       " (('i', 'x'), 89),\n",
       " (('v', '<E>'), 88),\n",
       " (('y', 'k'), 86),\n",
       " (('u', 'w'), 86),\n",
       " (('g', 'u'), 85),\n",
       " (('b', 'y'), 83),\n",
       " (('e', 'p'), 83),\n",
       " (('g', 'o'), 83),\n",
       " (('s', 'k'), 82),\n",
       " (('u', 't'), 82),\n",
       " (('a', 'p'), 82),\n",
       " (('e', 'f'), 82),\n",
       " (('i', 'i'), 82),\n",
       " (('r', 'v'), 80),\n",
       " (('f', '<E>'), 80),\n",
       " (('t', 'u'), 78),\n",
       " (('y', 'z'), 78),\n",
       " (('<S>', 'u'), 78),\n",
       " (('l', 't'), 77),\n",
       " (('r', 'g'), 76),\n",
       " (('c', 'r'), 76),\n",
       " (('i', 'j'), 76),\n",
       " (('w', 'y'), 73),\n",
       " (('z', 'u'), 73),\n",
       " (('l', 'v'), 72),\n",
       " (('h', 't'), 71),\n",
       " (('j', '<E>'), 71),\n",
       " (('x', 't'), 70),\n",
       " (('o', 'i'), 69),\n",
       " (('e', 'u'), 69),\n",
       " (('o', 'k'), 68),\n",
       " (('b', 'd'), 65),\n",
       " (('a', 'o'), 63),\n",
       " (('p', 'i'), 61),\n",
       " (('s', 'c'), 60),\n",
       " (('d', 'l'), 60),\n",
       " (('l', 'm'), 60),\n",
       " (('a', 'q'), 60),\n",
       " (('f', 'o'), 60),\n",
       " (('p', 'o'), 59),\n",
       " (('n', 'k'), 58),\n",
       " (('w', 'n'), 58),\n",
       " (('u', 'h'), 58),\n",
       " (('e', 'j'), 55),\n",
       " (('n', 'v'), 55),\n",
       " (('s', 'r'), 55),\n",
       " (('o', 'z'), 54),\n",
       " (('i', 'p'), 53),\n",
       " (('l', 'b'), 52),\n",
       " (('i', 'q'), 52),\n",
       " (('w', '<E>'), 51),\n",
       " (('m', 'c'), 51),\n",
       " (('s', 'p'), 51),\n",
       " (('e', 'w'), 50),\n",
       " (('k', 'u'), 50),\n",
       " (('v', 'r'), 48),\n",
       " (('u', 'g'), 47),\n",
       " (('o', 'x'), 45),\n",
       " (('u', 'z'), 45),\n",
       " (('z', 'z'), 45),\n",
       " (('j', 'h'), 45),\n",
       " (('b', 'u'), 45),\n",
       " (('o', 'g'), 44),\n",
       " (('n', 'r'), 44),\n",
       " (('f', 'f'), 44),\n",
       " (('n', 'j'), 44),\n",
       " (('z', 'h'), 43),\n",
       " (('c', 'c'), 42),\n",
       " (('r', 'b'), 41),\n",
       " (('x', 'o'), 41),\n",
       " (('b', 'h'), 41),\n",
       " (('p', 'p'), 39),\n",
       " (('x', 'l'), 39),\n",
       " (('h', 'v'), 39),\n",
       " (('b', 'b'), 38),\n",
       " (('m', 'p'), 38),\n",
       " (('x', 'x'), 38),\n",
       " (('u', 'v'), 37),\n",
       " (('x', 'e'), 36),\n",
       " (('w', 'o'), 36),\n",
       " (('c', 't'), 35),\n",
       " (('z', 'm'), 35),\n",
       " (('t', 's'), 35),\n",
       " (('m', 's'), 35),\n",
       " (('c', 'u'), 35),\n",
       " (('o', 'f'), 34),\n",
       " (('u', 'x'), 34),\n",
       " (('k', 'w'), 34),\n",
       " (('p', '<E>'), 33),\n",
       " (('g', 'l'), 32),\n",
       " (('z', 'r'), 32),\n",
       " (('d', 'n'), 31),\n",
       " (('g', 't'), 31),\n",
       " (('g', 'y'), 31),\n",
       " (('h', 's'), 31),\n",
       " (('x', 's'), 31),\n",
       " (('g', 's'), 30),\n",
       " (('x', 'y'), 30),\n",
       " (('y', 'g'), 30),\n",
       " (('d', 'm'), 30),\n",
       " (('d', 's'), 29),\n",
       " (('h', 'k'), 29),\n",
       " (('y', 'x'), 28),\n",
       " (('q', '<E>'), 28),\n",
       " (('g', 'n'), 27),\n",
       " (('y', 'b'), 27),\n",
       " (('g', 'w'), 26),\n",
       " (('n', 'h'), 26),\n",
       " (('k', 'n'), 26),\n",
       " (('g', 'g'), 25),\n",
       " (('d', 'g'), 25),\n",
       " (('l', 'c'), 25),\n",
       " (('r', 'j'), 25),\n",
       " (('w', 'u'), 25),\n",
       " (('l', 'k'), 24),\n",
       " (('m', 'd'), 24),\n",
       " (('s', 'w'), 24),\n",
       " (('s', 'n'), 24),\n",
       " (('h', 'd'), 24),\n",
       " (('w', 'h'), 23),\n",
       " (('y', 'j'), 23),\n",
       " (('y', 'y'), 23),\n",
       " (('r', 'z'), 23),\n",
       " (('d', 'w'), 23),\n",
       " (('w', 'r'), 22),\n",
       " (('t', 'n'), 22),\n",
       " (('l', 'f'), 22),\n",
       " (('y', 'h'), 22),\n",
       " (('r', 'w'), 21),\n",
       " (('s', 'b'), 21),\n",
       " (('m', 'n'), 20),\n",
       " (('f', 'l'), 20),\n",
       " (('w', 's'), 20),\n",
       " (('k', 'k'), 20),\n",
       " (('h', 'z'), 20),\n",
       " (('g', 'd'), 19),\n",
       " (('l', 'h'), 19),\n",
       " (('n', 'm'), 19),\n",
       " (('x', 'z'), 19),\n",
       " (('u', 'f'), 19),\n",
       " (('f', 't'), 18),\n",
       " (('l', 'r'), 18),\n",
       " (('p', 't'), 17),\n",
       " (('t', 'c'), 17),\n",
       " (('k', 't'), 17),\n",
       " (('d', 'v'), 17),\n",
       " (('u', 'p'), 16),\n",
       " (('p', 'l'), 16),\n",
       " (('l', 'w'), 16),\n",
       " (('p', 's'), 16),\n",
       " (('o', 'j'), 16),\n",
       " (('r', 'q'), 16),\n",
       " (('y', 'p'), 15),\n",
       " (('l', 'p'), 15),\n",
       " (('t', 'v'), 15),\n",
       " (('r', 'p'), 14),\n",
       " (('l', 'n'), 14),\n",
       " (('e', 'q'), 14),\n",
       " (('f', 'y'), 14),\n",
       " (('s', 'v'), 14),\n",
       " (('u', 'j'), 14),\n",
       " (('v', 'l'), 14),\n",
       " (('q', 'a'), 13),\n",
       " (('u', 'y'), 13),\n",
       " (('q', 'i'), 13),\n",
       " (('w', 'l'), 13),\n",
       " (('p', 'y'), 12),\n",
       " (('y', 'f'), 12),\n",
       " (('c', 'q'), 11),\n",
       " (('j', 'r'), 11),\n",
       " (('n', 'w'), 11),\n",
       " (('n', 'f'), 11),\n",
       " (('t', 'w'), 11),\n",
       " (('m', 'z'), 11),\n",
       " (('u', 'o'), 10),\n",
       " (('f', 'u'), 10),\n",
       " (('l', 'z'), 10),\n",
       " (('h', 'w'), 10),\n",
       " (('u', 'q'), 10),\n",
       " (('j', 'y'), 10),\n",
       " (('s', 'z'), 10),\n",
       " (('s', 'd'), 9),\n",
       " (('j', 'l'), 9),\n",
       " (('d', 'j'), 9),\n",
       " (('k', 'm'), 9),\n",
       " (('r', 'f'), 9),\n",
       " (('h', 'j'), 9),\n",
       " (('v', 'n'), 8),\n",
       " (('n', 'b'), 8),\n",
       " (('i', 'w'), 8),\n",
       " (('h', 'b'), 8),\n",
       " (('b', 's'), 8),\n",
       " (('w', 't'), 8),\n",
       " (('w', 'd'), 8),\n",
       " (('v', 'v'), 7),\n",
       " (('v', 'u'), 7),\n",
       " (('j', 's'), 7),\n",
       " (('m', 'j'), 7),\n",
       " (('f', 's'), 6),\n",
       " (('l', 'g'), 6),\n",
       " (('l', 'j'), 6),\n",
       " (('j', 'w'), 6),\n",
       " (('n', 'x'), 6),\n",
       " (('y', 'q'), 6),\n",
       " (('w', 'k'), 6),\n",
       " (('g', 'm'), 6),\n",
       " (('x', 'u'), 5),\n",
       " (('m', 'h'), 5),\n",
       " (('m', 'l'), 5),\n",
       " (('j', 'm'), 5),\n",
       " (('c', 's'), 5),\n",
       " (('j', 'v'), 5),\n",
       " (('n', 'p'), 5),\n",
       " (('d', 'f'), 5),\n",
       " (('x', 'd'), 5),\n",
       " (('z', 'b'), 4),\n",
       " (('f', 'n'), 4),\n",
       " (('x', 'c'), 4),\n",
       " (('m', 't'), 4),\n",
       " (('t', 'm'), 4),\n",
       " (('z', 'n'), 4),\n",
       " (('z', 't'), 4),\n",
       " (('p', 'u'), 4),\n",
       " (('c', 'z'), 4),\n",
       " (('b', 'n'), 4),\n",
       " (('z', 's'), 4),\n",
       " (('f', 'w'), 4),\n",
       " (('d', 't'), 4),\n",
       " (('j', 'd'), 4),\n",
       " (('j', 'c'), 4),\n",
       " (('y', 'w'), 4),\n",
       " (('v', 'k'), 3),\n",
       " (('x', 'w'), 3),\n",
       " (('t', 'j'), 3),\n",
       " (('c', 'j'), 3),\n",
       " (('q', 'w'), 3),\n",
       " (('g', 'b'), 3),\n",
       " (('o', 'q'), 3),\n",
       " (('r', 'x'), 3),\n",
       " (('d', 'c'), 3),\n",
       " (('g', 'j'), 3),\n",
       " (('x', 'f'), 3),\n",
       " (('z', 'w'), 3),\n",
       " (('d', 'k'), 3),\n",
       " (('u', 'u'), 3),\n",
       " (('m', 'v'), 3),\n",
       " (('c', 'x'), 3),\n",
       " (('l', 'q'), 3),\n",
       " (('p', 'b'), 2),\n",
       " (('t', 'g'), 2),\n",
       " (('q', 's'), 2),\n",
       " (('t', 'x'), 2),\n",
       " (('f', 'k'), 2),\n",
       " (('b', 't'), 2),\n",
       " (('j', 'n'), 2),\n",
       " (('k', 'c'), 2),\n",
       " (('z', 'k'), 2),\n",
       " (('s', 'j'), 2),\n",
       " (('s', 'f'), 2),\n",
       " (('z', 'j'), 2),\n",
       " (('n', 'q'), 2),\n",
       " (('f', 'z'), 2),\n",
       " (('h', 'g'), 2),\n",
       " (('w', 'w'), 2),\n",
       " (('k', 'j'), 2),\n",
       " (('j', 'k'), 2),\n",
       " (('w', 'm'), 2),\n",
       " (('z', 'c'), 2),\n",
       " (('z', 'v'), 2),\n",
       " (('w', 'f'), 2),\n",
       " (('q', 'm'), 2),\n",
       " (('k', 'z'), 2),\n",
       " (('j', 'j'), 2),\n",
       " (('z', 'p'), 2),\n",
       " (('j', 't'), 2),\n",
       " (('k', 'b'), 2),\n",
       " (('m', 'w'), 2),\n",
       " (('h', 'f'), 2),\n",
       " (('c', 'g'), 2),\n",
       " (('t', 'f'), 2),\n",
       " (('h', 'c'), 2),\n",
       " (('q', 'o'), 2),\n",
       " (('k', 'd'), 2),\n",
       " (('k', 'v'), 2),\n",
       " (('s', 'g'), 2),\n",
       " (('z', 'd'), 2),\n",
       " (('q', 'r'), 1),\n",
       " (('d', 'z'), 1),\n",
       " (('p', 'j'), 1),\n",
       " (('q', 'l'), 1),\n",
       " (('p', 'f'), 1),\n",
       " (('q', 'e'), 1),\n",
       " (('b', 'c'), 1),\n",
       " (('c', 'd'), 1),\n",
       " (('m', 'f'), 1),\n",
       " (('p', 'n'), 1),\n",
       " (('w', 'b'), 1),\n",
       " (('p', 'c'), 1),\n",
       " (('h', 'p'), 1),\n",
       " (('f', 'h'), 1),\n",
       " (('b', 'j'), 1),\n",
       " (('f', 'g'), 1),\n",
       " (('z', 'g'), 1),\n",
       " (('c', 'p'), 1),\n",
       " (('p', 'k'), 1),\n",
       " (('p', 'm'), 1),\n",
       " (('x', 'n'), 1),\n",
       " (('s', 'q'), 1),\n",
       " (('k', 'f'), 1),\n",
       " (('m', 'k'), 1),\n",
       " (('x', 'h'), 1),\n",
       " (('g', 'f'), 1),\n",
       " (('v', 'b'), 1),\n",
       " (('j', 'p'), 1),\n",
       " (('g', 'z'), 1),\n",
       " (('v', 'd'), 1),\n",
       " (('d', 'b'), 1),\n",
       " (('v', 'h'), 1),\n",
       " (('h', 'h'), 1),\n",
       " (('g', 'v'), 1),\n",
       " (('d', 'q'), 1),\n",
       " (('x', 'b'), 1),\n",
       " (('w', 'z'), 1),\n",
       " (('h', 'q'), 1),\n",
       " (('j', 'b'), 1),\n",
       " (('x', 'm'), 1),\n",
       " (('w', 'g'), 1),\n",
       " (('t', 'b'), 1),\n",
       " (('z', 'x'), 1)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(b.items(),key=lambda kv:-kv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "24ae25e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5eb534b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.zeros((3,5),dtype=torch.int32)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8d4df46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int32"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "06c95aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=torch.zeros((27,27),dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "132e436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars=sorted(list(set(\"\".join(words))))\n",
    "stoi={s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2b04a2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5442e06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 0: '.'}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos={s:i for i,s in stoi.items()}\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0f394707",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words:\n",
    "    chs=['.']+list(w)+['.']\n",
    "    for ch1, ch2 in zip(chs,chs[1:]):\n",
    "        ix1=stoi[ch1]\n",
    "        ix2=stoi[ch2]\n",
    "        N[ix1,ix2]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "11c9d1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0, 4410, 1306, 1542, 1690, 1531,  417,  669,  874,  591, 2422, 2963,\n",
       "         1572, 2538, 1146,  394,  515,   92, 1639, 2055, 1308,   78,  376,  307,\n",
       "          134,  535,  929],\n",
       "        [6640,  556,  541,  470, 1042,  692,  134,  168, 2332, 1650,  175,  568,\n",
       "         2528, 1634, 5438,   63,   82,   60, 3264, 1118,  687,  381,  834,  161,\n",
       "          182, 2050,  435],\n",
       "        [ 114,  321,   38,    1,   65,  655,    0,    0,   41,  217,    1,    0,\n",
       "          103,    0,    4,  105,    0,    0,  842,    8,    2,   45,    0,    0,\n",
       "            0,   83,    0],\n",
       "        [  97,  815,    0,   42,    1,  551,    0,    2,  664,  271,    3,  316,\n",
       "          116,    0,    0,  380,    1,   11,   76,    5,   35,   35,    0,    0,\n",
       "            3,  104,    4],\n",
       "        [ 516, 1303,    1,    3,  149, 1283,    5,   25,  118,  674,    9,    3,\n",
       "           60,   30,   31,  378,    0,    1,  424,   29,    4,   92,   17,   23,\n",
       "            0,  317,    1],\n",
       "        [3983,  679,  121,  153,  384, 1271,   82,  125,  152,  818,   55,  178,\n",
       "         3248,  769, 2675,  269,   83,   14, 1958,  861,  580,   69,  463,   50,\n",
       "          132, 1070,  181],\n",
       "        [  80,  242,    0,    0,    0,  123,   44,    1,    1,  160,    0,    2,\n",
       "           20,    0,    4,   60,    0,    0,  114,    6,   18,   10,    0,    4,\n",
       "            0,   14,    2],\n",
       "        [ 108,  330,    3,    0,   19,  334,    1,   25,  360,  190,    3,    0,\n",
       "           32,    6,   27,   83,    0,    0,  201,   30,   31,   85,    1,   26,\n",
       "            0,   31,    1],\n",
       "        [2409, 2244,    8,    2,   24,  674,    2,    2,    1,  729,    9,   29,\n",
       "          185,  117,  138,  287,    1,    1,  204,   31,   71,  166,   39,   10,\n",
       "            0,  213,   20],\n",
       "        [2489, 2445,  110,  509,  440, 1653,  101,  428,   95,   82,   76,  445,\n",
       "         1345,  427, 2126,  588,   53,   52,  849, 1316,  541,  109,  269,    8,\n",
       "           89,  779,  277],\n",
       "        [  71, 1473,    1,    4,    4,  440,    0,    0,   45,  119,    2,    2,\n",
       "            9,    5,    2,  479,    1,    0,   11,    7,    2,  202,    5,    6,\n",
       "            0,   10,    0],\n",
       "        [ 363, 1731,    2,    2,    2,  895,    1,    0,  307,  509,    2,   20,\n",
       "          139,    9,   26,  344,    0,    0,  109,   95,   17,   50,    2,   34,\n",
       "            0,  379,    2],\n",
       "        [1314, 2623,   52,   25,  138, 2921,   22,    6,   19, 2480,    6,   24,\n",
       "         1345,   60,   14,  692,   15,    3,   18,   94,   77,  324,   72,   16,\n",
       "            0, 1588,   10],\n",
       "        [ 516, 2590,  112,   51,   24,  818,    1,    0,    5, 1256,    7,    1,\n",
       "            5,  168,   20,  452,   38,    0,   97,   35,    4,  139,    3,    2,\n",
       "            0,  287,   11],\n",
       "        [6763, 2977,    8,  213,  704, 1359,   11,  273,   26, 1725,   44,   58,\n",
       "          195,   19, 1906,  496,    5,    2,   44,  278,  443,   96,   55,   11,\n",
       "            6,  465,  145],\n",
       "        [ 855,  149,  140,  114,  190,  132,   34,   44,  171,   69,   16,   68,\n",
       "          619,  261, 2411,  115,   95,    3, 1059,  504,  118,  275,  176,  114,\n",
       "           45,  103,   54],\n",
       "        [  33,  209,    2,    1,    0,  197,    1,    0,  204,   61,    1,    1,\n",
       "           16,    1,    1,   59,   39,    0,  151,   16,   17,    4,    0,    0,\n",
       "            0,   12,    0],\n",
       "        [  28,   13,    0,    0,    0,    1,    0,    0,    0,   13,    0,    0,\n",
       "            1,    2,    0,    2,    0,    0,    1,    2,    0,  206,    0,    3,\n",
       "            0,    0,    0],\n",
       "        [1377, 2356,   41,   99,  187, 1697,    9,   76,  121, 3033,   25,   90,\n",
       "          413,  162,  140,  869,   14,   16,  425,  190,  208,  252,   80,   21,\n",
       "            3,  773,   23],\n",
       "        [1169, 1201,   21,   60,    9,  884,    2,    2, 1285,  684,    2,   82,\n",
       "          279,   90,   24,  531,   51,    1,   55,  461,  765,  185,   14,   24,\n",
       "            0,  215,   10],\n",
       "        [ 483, 1027,    1,   17,    0,  716,    2,    2,  647,  532,    3,    0,\n",
       "          134,    4,   22,  667,    0,    0,  352,   35,  374,   78,   15,   11,\n",
       "            2,  341,  105],\n",
       "        [ 155,  163,  103,  103,  136,  169,   19,   47,   58,  121,   14,   93,\n",
       "          301,  154,  275,   10,   16,   10,  414,  474,   82,    3,   37,   86,\n",
       "           34,   13,   45],\n",
       "        [  88,  642,    1,    0,    1,  568,    0,    0,    1,  911,    0,    3,\n",
       "           14,    0,    8,  153,    0,    0,   48,    0,    0,    7,    7,    0,\n",
       "            0,  121,    0],\n",
       "        [  51,  280,    1,    0,    8,  149,    2,    1,   23,  148,    0,    6,\n",
       "           13,    2,   58,   36,    0,    0,   22,   20,    8,   25,    0,    2,\n",
       "            0,   73,    1],\n",
       "        [ 164,  103,    1,    4,    5,   36,    3,    0,    1,  102,    0,    0,\n",
       "           39,    1,    1,   41,    0,    0,    0,   31,   70,    5,    0,    3,\n",
       "           38,   30,   19],\n",
       "        [2007, 2143,   27,  115,  272,  301,   12,   30,   22,  192,   23,   86,\n",
       "         1104,  148, 1826,  271,   15,    6,  291,  401,  104,  141,  106,    4,\n",
       "           28,   23,   78],\n",
       "        [ 160,  860,    4,    2,    2,  373,    0,    1,   43,  364,    2,    2,\n",
       "          123,   35,    4,  110,    2,    0,   32,    4,    4,   73,    2,    3,\n",
       "            1,  147,   45]], dtype=torch.int32)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "86161985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(N[3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a410fb19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0, 4410, 1306, 1542, 1690, 1531,  417,  669,  874,  591, 2422, 2963,\n",
       "        1572, 2538, 1146,  394,  515,   92, 1639, 2055, 1308,   78,  376,  307,\n",
       "         134,  535,  929], dtype=torch.int32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "629ff46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.1377, 0.0408, 0.0481, 0.0528, 0.0478, 0.0130, 0.0209, 0.0273,\n",
      "        0.0184, 0.0756, 0.0925, 0.0491, 0.0792, 0.0358, 0.0123, 0.0161, 0.0029,\n",
      "        0.0512, 0.0642, 0.0408, 0.0024, 0.0117, 0.0096, 0.0042, 0.0167, 0.0290])\n"
     ]
    }
   ],
   "source": [
    "p=N[0].float()\n",
    "p/=p.sum()\n",
    "print(p) #probablity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0990ab34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'j'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g=torch.Generator().manual_seed(2147483647)\n",
    "ix=torch.multinomial(p,num_samples=1,replacement=True,generator=g).item()\n",
    "itos[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6eac1235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6064, 0.3033, 0.0903])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ge=torch.Generator().manual_seed(2147483647)\n",
    "pe=torch.rand(3,generator=ge)\n",
    "pe=pe/pe.sum()\n",
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "57fa9c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 2, 0, 0, 2, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 2, 0,\n",
       "        0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 1,\n",
       "        0, 0, 1, 1])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multinomial(pe,num_samples=100,replacement=True,generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "908fc9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[32033.],\n",
       "        [33885.],\n",
       "        [ 2645.],\n",
       "        [ 3532.],\n",
       "        [ 5496.],\n",
       "        [20423.],\n",
       "        [  905.],\n",
       "        [ 1927.],\n",
       "        [ 7616.],\n",
       "        [17701.],\n",
       "        [ 2900.],\n",
       "        [ 5040.],\n",
       "        [13958.],\n",
       "        [ 6642.],\n",
       "        [18327.],\n",
       "        [ 7934.],\n",
       "        [ 1026.],\n",
       "        [  272.],\n",
       "        [12700.],\n",
       "        [ 8106.],\n",
       "        [ 5570.],\n",
       "        [ 3135.],\n",
       "        [ 2573.],\n",
       "        [  929.],\n",
       "        [  697.],\n",
       "        [ 9776.],\n",
       "        [ 2398.]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = N.float()\n",
    "P.sum(1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7c271dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 1.3767e-01, 4.0770e-02, 4.8138e-02, 5.2758e-02, 4.7794e-02,\n",
       "         1.3018e-02, 2.0885e-02, 2.7284e-02, 1.8450e-02, 7.5610e-02, 9.2498e-02,\n",
       "         4.9074e-02, 7.9231e-02, 3.5776e-02, 1.2300e-02, 1.6077e-02, 2.8720e-03,\n",
       "         5.1166e-02, 6.4153e-02, 4.0833e-02, 2.4350e-03, 1.1738e-02, 9.5839e-03,\n",
       "         4.1832e-03, 1.6702e-02, 2.9001e-02],\n",
       "        [1.9596e-01, 1.6408e-02, 1.5966e-02, 1.3870e-02, 3.0751e-02, 2.0422e-02,\n",
       "         3.9546e-03, 4.9579e-03, 6.8821e-02, 4.8694e-02, 5.1645e-03, 1.6763e-02,\n",
       "         7.4605e-02, 4.8222e-02, 1.6048e-01, 1.8592e-03, 2.4199e-03, 1.7707e-03,\n",
       "         9.6326e-02, 3.2994e-02, 2.0274e-02, 1.1244e-02, 2.4613e-02, 4.7514e-03,\n",
       "         5.3711e-03, 6.0499e-02, 1.2838e-02],\n",
       "        [4.3100e-02, 1.2136e-01, 1.4367e-02, 3.7807e-04, 2.4575e-02, 2.4764e-01,\n",
       "         0.0000e+00, 0.0000e+00, 1.5501e-02, 8.2042e-02, 3.7807e-04, 0.0000e+00,\n",
       "         3.8941e-02, 0.0000e+00, 1.5123e-03, 3.9698e-02, 0.0000e+00, 0.0000e+00,\n",
       "         3.1834e-01, 3.0246e-03, 7.5614e-04, 1.7013e-02, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 3.1380e-02, 0.0000e+00],\n",
       "        [2.7463e-02, 2.3075e-01, 0.0000e+00, 1.1891e-02, 2.8313e-04, 1.5600e-01,\n",
       "         0.0000e+00, 5.6625e-04, 1.8800e-01, 7.6727e-02, 8.4938e-04, 8.9468e-02,\n",
       "         3.2843e-02, 0.0000e+00, 0.0000e+00, 1.0759e-01, 2.8313e-04, 3.1144e-03,\n",
       "         2.1518e-02, 1.4156e-03, 9.9094e-03, 9.9094e-03, 0.0000e+00, 0.0000e+00,\n",
       "         8.4938e-04, 2.9445e-02, 1.1325e-03],\n",
       "        [9.3886e-02, 2.3708e-01, 1.8195e-04, 5.4585e-04, 2.7111e-02, 2.3344e-01,\n",
       "         9.0975e-04, 4.5488e-03, 2.1470e-02, 1.2263e-01, 1.6376e-03, 5.4585e-04,\n",
       "         1.0917e-02, 5.4585e-03, 5.6405e-03, 6.8777e-02, 0.0000e+00, 1.8195e-04,\n",
       "         7.7147e-02, 5.2766e-03, 7.2780e-04, 1.6739e-02, 3.0932e-03, 4.1849e-03,\n",
       "         0.0000e+00, 5.7678e-02, 1.8195e-04],\n",
       "        [1.9503e-01, 3.3247e-02, 5.9247e-03, 7.4916e-03, 1.8802e-02, 6.2234e-02,\n",
       "         4.0151e-03, 6.1206e-03, 7.4426e-03, 4.0053e-02, 2.6930e-03, 8.7157e-03,\n",
       "         1.5904e-01, 3.7654e-02, 1.3098e-01, 1.3171e-02, 4.0640e-03, 6.8550e-04,\n",
       "         9.5872e-02, 4.2158e-02, 2.8399e-02, 3.3785e-03, 2.2671e-02, 2.4482e-03,\n",
       "         6.4633e-03, 5.2392e-02, 8.8626e-03],\n",
       "        [8.8398e-02, 2.6740e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3591e-01,\n",
       "         4.8619e-02, 1.1050e-03, 1.1050e-03, 1.7680e-01, 0.0000e+00, 2.2099e-03,\n",
       "         2.2099e-02, 0.0000e+00, 4.4199e-03, 6.6298e-02, 0.0000e+00, 0.0000e+00,\n",
       "         1.2597e-01, 6.6298e-03, 1.9890e-02, 1.1050e-02, 0.0000e+00, 4.4199e-03,\n",
       "         0.0000e+00, 1.5470e-02, 2.2099e-03],\n",
       "        [5.6046e-02, 1.7125e-01, 1.5568e-03, 0.0000e+00, 9.8599e-03, 1.7333e-01,\n",
       "         5.1894e-04, 1.2974e-02, 1.8682e-01, 9.8599e-02, 1.5568e-03, 0.0000e+00,\n",
       "         1.6606e-02, 3.1136e-03, 1.4011e-02, 4.3072e-02, 0.0000e+00, 0.0000e+00,\n",
       "         1.0431e-01, 1.5568e-02, 1.6087e-02, 4.4110e-02, 5.1894e-04, 1.3492e-02,\n",
       "         0.0000e+00, 1.6087e-02, 5.1894e-04],\n",
       "        [3.1631e-01, 2.9464e-01, 1.0504e-03, 2.6261e-04, 3.1513e-03, 8.8498e-02,\n",
       "         2.6261e-04, 2.6261e-04, 1.3130e-04, 9.5720e-02, 1.1817e-03, 3.8078e-03,\n",
       "         2.4291e-02, 1.5362e-02, 1.8120e-02, 3.7684e-02, 1.3130e-04, 1.3130e-04,\n",
       "         2.6786e-02, 4.0704e-03, 9.3225e-03, 2.1796e-02, 5.1208e-03, 1.3130e-03,\n",
       "         0.0000e+00, 2.7967e-02, 2.6261e-03],\n",
       "        [1.4061e-01, 1.3813e-01, 6.2143e-03, 2.8755e-02, 2.4857e-02, 9.3385e-02,\n",
       "         5.7059e-03, 2.4179e-02, 5.3669e-03, 4.6325e-03, 4.2935e-03, 2.5140e-02,\n",
       "         7.5984e-02, 2.4123e-02, 1.2011e-01, 3.3218e-02, 2.9942e-03, 2.9377e-03,\n",
       "         4.7963e-02, 7.4346e-02, 3.0563e-02, 6.1578e-03, 1.5197e-02, 4.5195e-04,\n",
       "         5.0280e-03, 4.4009e-02, 1.5649e-02],\n",
       "        [2.4483e-02, 5.0793e-01, 3.4483e-04, 1.3793e-03, 1.3793e-03, 1.5172e-01,\n",
       "         0.0000e+00, 0.0000e+00, 1.5517e-02, 4.1034e-02, 6.8966e-04, 6.8966e-04,\n",
       "         3.1034e-03, 1.7241e-03, 6.8966e-04, 1.6517e-01, 3.4483e-04, 0.0000e+00,\n",
       "         3.7931e-03, 2.4138e-03, 6.8966e-04, 6.9655e-02, 1.7241e-03, 2.0690e-03,\n",
       "         0.0000e+00, 3.4483e-03, 0.0000e+00],\n",
       "        [7.2024e-02, 3.4345e-01, 3.9683e-04, 3.9683e-04, 3.9683e-04, 1.7758e-01,\n",
       "         1.9841e-04, 0.0000e+00, 6.0913e-02, 1.0099e-01, 3.9683e-04, 3.9683e-03,\n",
       "         2.7579e-02, 1.7857e-03, 5.1587e-03, 6.8254e-02, 0.0000e+00, 0.0000e+00,\n",
       "         2.1627e-02, 1.8849e-02, 3.3730e-03, 9.9206e-03, 3.9683e-04, 6.7460e-03,\n",
       "         0.0000e+00, 7.5198e-02, 3.9683e-04],\n",
       "        [9.4140e-02, 1.8792e-01, 3.7255e-03, 1.7911e-03, 9.8868e-03, 2.0927e-01,\n",
       "         1.5762e-03, 4.2986e-04, 1.3612e-03, 1.7768e-01, 4.2986e-04, 1.7194e-03,\n",
       "         9.6361e-02, 4.2986e-03, 1.0030e-03, 4.9577e-02, 1.0747e-03, 2.1493e-04,\n",
       "         1.2896e-03, 6.7345e-03, 5.5165e-03, 2.3212e-02, 5.1583e-03, 1.1463e-03,\n",
       "         0.0000e+00, 1.1377e-01, 7.1644e-04],\n",
       "        [7.7687e-02, 3.8994e-01, 1.6862e-02, 7.6784e-03, 3.6134e-03, 1.2316e-01,\n",
       "         1.5056e-04, 0.0000e+00, 7.5279e-04, 1.8910e-01, 1.0539e-03, 1.5056e-04,\n",
       "         7.5279e-04, 2.5294e-02, 3.0111e-03, 6.8052e-02, 5.7212e-03, 0.0000e+00,\n",
       "         1.4604e-02, 5.2695e-03, 6.0223e-04, 2.0927e-02, 4.5167e-04, 3.0111e-04,\n",
       "         0.0000e+00, 4.3210e-02, 1.6561e-03],\n",
       "        [3.6902e-01, 1.6244e-01, 4.3651e-04, 1.1622e-02, 3.8413e-02, 7.4153e-02,\n",
       "         6.0021e-04, 1.4896e-02, 1.4187e-03, 9.4123e-02, 2.4008e-03, 3.1647e-03,\n",
       "         1.0640e-02, 1.0367e-03, 1.0400e-01, 2.7064e-02, 2.7282e-04, 1.0913e-04,\n",
       "         2.4008e-03, 1.5169e-02, 2.4172e-02, 5.2382e-03, 3.0010e-03, 6.0021e-04,\n",
       "         3.2739e-04, 2.5372e-02, 7.9118e-03],\n",
       "        [1.0776e-01, 1.8780e-02, 1.7646e-02, 1.4369e-02, 2.3948e-02, 1.6637e-02,\n",
       "         4.2854e-03, 5.5458e-03, 2.1553e-02, 8.6967e-03, 2.0166e-03, 8.5707e-03,\n",
       "         7.8019e-02, 3.2896e-02, 3.0388e-01, 1.4495e-02, 1.1974e-02, 3.7812e-04,\n",
       "         1.3348e-01, 6.3524e-02, 1.4873e-02, 3.4661e-02, 2.2183e-02, 1.4369e-02,\n",
       "         5.6718e-03, 1.2982e-02, 6.8062e-03],\n",
       "        [3.2164e-02, 2.0370e-01, 1.9493e-03, 9.7466e-04, 0.0000e+00, 1.9201e-01,\n",
       "         9.7466e-04, 0.0000e+00, 1.9883e-01, 5.9454e-02, 9.7466e-04, 9.7466e-04,\n",
       "         1.5595e-02, 9.7466e-04, 9.7466e-04, 5.7505e-02, 3.8012e-02, 0.0000e+00,\n",
       "         1.4717e-01, 1.5595e-02, 1.6569e-02, 3.8986e-03, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.1696e-02, 0.0000e+00],\n",
       "        [1.0294e-01, 4.7794e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6765e-03,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7794e-02, 0.0000e+00, 0.0000e+00,\n",
       "         3.6765e-03, 7.3529e-03, 0.0000e+00, 7.3529e-03, 0.0000e+00, 0.0000e+00,\n",
       "         3.6765e-03, 7.3529e-03, 0.0000e+00, 7.5735e-01, 0.0000e+00, 1.1029e-02,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0843e-01, 1.8551e-01, 3.2283e-03, 7.7953e-03, 1.4724e-02, 1.3362e-01,\n",
       "         7.0866e-04, 5.9843e-03, 9.5276e-03, 2.3882e-01, 1.9685e-03, 7.0866e-03,\n",
       "         3.2520e-02, 1.2756e-02, 1.1024e-02, 6.8425e-02, 1.1024e-03, 1.2598e-03,\n",
       "         3.3465e-02, 1.4961e-02, 1.6378e-02, 1.9843e-02, 6.2992e-03, 1.6535e-03,\n",
       "         2.3622e-04, 6.0866e-02, 1.8110e-03],\n",
       "        [1.4421e-01, 1.4816e-01, 2.5907e-03, 7.4019e-03, 1.1103e-03, 1.0906e-01,\n",
       "         2.4673e-04, 2.4673e-04, 1.5852e-01, 8.4382e-02, 2.4673e-04, 1.0116e-02,\n",
       "         3.4419e-02, 1.1103e-02, 2.9608e-03, 6.5507e-02, 6.2916e-03, 1.2337e-04,\n",
       "         6.7851e-03, 5.6871e-02, 9.4375e-02, 2.2823e-02, 1.7271e-03, 2.9608e-03,\n",
       "         0.0000e+00, 2.6524e-02, 1.2337e-03],\n",
       "        [8.6715e-02, 1.8438e-01, 1.7953e-04, 3.0521e-03, 0.0000e+00, 1.2855e-01,\n",
       "         3.5907e-04, 3.5907e-04, 1.1616e-01, 9.5512e-02, 5.3860e-04, 0.0000e+00,\n",
       "         2.4057e-02, 7.1813e-04, 3.9497e-03, 1.1975e-01, 0.0000e+00, 0.0000e+00,\n",
       "         6.3196e-02, 6.2837e-03, 6.7145e-02, 1.4004e-02, 2.6930e-03, 1.9749e-03,\n",
       "         3.5907e-04, 6.1221e-02, 1.8851e-02],\n",
       "        [4.9442e-02, 5.1994e-02, 3.2855e-02, 3.2855e-02, 4.3381e-02, 5.3907e-02,\n",
       "         6.0606e-03, 1.4992e-02, 1.8501e-02, 3.8596e-02, 4.4657e-03, 2.9665e-02,\n",
       "         9.6013e-02, 4.9123e-02, 8.7719e-02, 3.1898e-03, 5.1037e-03, 3.1898e-03,\n",
       "         1.3206e-01, 1.5120e-01, 2.6156e-02, 9.5694e-04, 1.1802e-02, 2.7432e-02,\n",
       "         1.0845e-02, 4.1467e-03, 1.4354e-02],\n",
       "        [3.4201e-02, 2.4951e-01, 3.8865e-04, 0.0000e+00, 3.8865e-04, 2.2075e-01,\n",
       "         0.0000e+00, 0.0000e+00, 3.8865e-04, 3.5406e-01, 0.0000e+00, 1.1660e-03,\n",
       "         5.4411e-03, 0.0000e+00, 3.1092e-03, 5.9464e-02, 0.0000e+00, 0.0000e+00,\n",
       "         1.8655e-02, 0.0000e+00, 0.0000e+00, 2.7206e-03, 2.7206e-03, 0.0000e+00,\n",
       "         0.0000e+00, 4.7027e-02, 0.0000e+00],\n",
       "        [5.4898e-02, 3.0140e-01, 1.0764e-03, 0.0000e+00, 8.6114e-03, 1.6039e-01,\n",
       "         2.1529e-03, 1.0764e-03, 2.4758e-02, 1.5931e-01, 0.0000e+00, 6.4586e-03,\n",
       "         1.3994e-02, 2.1529e-03, 6.2433e-02, 3.8751e-02, 0.0000e+00, 0.0000e+00,\n",
       "         2.3681e-02, 2.1529e-02, 8.6114e-03, 2.6911e-02, 0.0000e+00, 2.1529e-03,\n",
       "         0.0000e+00, 7.8579e-02, 1.0764e-03],\n",
       "        [2.3529e-01, 1.4778e-01, 1.4347e-03, 5.7389e-03, 7.1736e-03, 5.1650e-02,\n",
       "         4.3042e-03, 0.0000e+00, 1.4347e-03, 1.4634e-01, 0.0000e+00, 0.0000e+00,\n",
       "         5.5954e-02, 1.4347e-03, 1.4347e-03, 5.8824e-02, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 4.4476e-02, 1.0043e-01, 7.1736e-03, 0.0000e+00, 4.3042e-03,\n",
       "         5.4519e-02, 4.3042e-02, 2.7260e-02],\n",
       "        [2.0530e-01, 2.1921e-01, 2.7619e-03, 1.1764e-02, 2.7823e-02, 3.0790e-02,\n",
       "         1.2275e-03, 3.0687e-03, 2.2504e-03, 1.9640e-02, 2.3527e-03, 8.7971e-03,\n",
       "         1.1293e-01, 1.5139e-02, 1.8678e-01, 2.7721e-02, 1.5344e-03, 6.1375e-04,\n",
       "         2.9767e-02, 4.1019e-02, 1.0638e-02, 1.4423e-02, 1.0843e-02, 4.0917e-04,\n",
       "         2.8642e-03, 2.3527e-03, 7.9787e-03],\n",
       "        [6.6722e-02, 3.5863e-01, 1.6681e-03, 8.3403e-04, 8.3403e-04, 1.5555e-01,\n",
       "         0.0000e+00, 4.1701e-04, 1.7932e-02, 1.5179e-01, 8.3403e-04, 8.3403e-04,\n",
       "         5.1293e-02, 1.4595e-02, 1.6681e-03, 4.5872e-02, 8.3403e-04, 0.0000e+00,\n",
       "         1.3344e-02, 1.6681e-03, 1.6681e-03, 3.0442e-02, 8.3403e-04, 1.2510e-03,\n",
       "         4.1701e-04, 6.1301e-02, 1.8766e-02]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = N.float()\n",
    "P=P/P.sum(1,keepdim=True)\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "db1f70a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junide.\n",
      "janasah.\n",
      "p.\n",
      "cony.\n",
      "a.\n",
      "nn.\n",
      "kohin.\n",
      "tolian.\n",
      "juee.\n",
      "ksahnaauranilevias.\n",
      "dedainrwieta.\n",
      "ssonielylarte.\n",
      "faveumerifontume.\n",
      "phynslenaruani.\n",
      "core.\n",
      "yaenon.\n",
      "ka.\n",
      "jabdinerimikimaynin.\n",
      "anaasn.\n",
      "ssorionsush.\n"
     ]
    }
   ],
   "source": [
    "#predict names\n",
    "P = (N+1).float()\n",
    "P=P/P.sum(1,keepdim=True)\n",
    "g=torch.Generator().manual_seed(2147483647)\n",
    "for i in range(20):\n",
    "    ix=0\n",
    "    out=[]\n",
    "    while True:\n",
    "        p=P[ix]\n",
    "        #p=N[ix].float()\n",
    "        #p/=p.sum()\n",
    "        ix=torch.multinomial(p,num_samples=1,replacement=True,generator=g).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix==0:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1fd1c770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".-j:0.0756-2.5826\n",
      "j-a:0.5036-0.6860\n",
      "a-y:0.0605-2.8054\n",
      "y-a:0.2187-1.5200\n",
      "a-n:0.1604-1.8302\n",
      "n-t:0.0242-3.7218\n",
      "t-.:0.0865-2.4479\n",
      "log_likelihood=tensor(-15.5939)\n",
      "nll=tensor(15.5939)\n",
      "2.227701425552368\n"
     ]
    }
   ],
   "source": [
    "#evaluate quality of the model\n",
    "log_likelihood=0.0\n",
    "n=0\n",
    "#for w in words:\n",
    "for w in ['jayant']:\n",
    "    chs=['.']+list(w)+['.']\n",
    "    for ch1, ch2 in zip(chs,chs[1:]):\n",
    "        ix1=stoi[ch1]\n",
    "        ix2=stoi[ch2]\n",
    "        prob = P[ix1,ix2]\n",
    "        logprob = torch.log(prob)\n",
    "        log_likelihood += logprob\n",
    "        n+=1\n",
    "        print(f'{ch1}-{ch2}:{prob:.4f}{logprob:.4f}')\n",
    "print(f'{log_likelihood=}')\n",
    "nll = -log_likelihood\n",
    "print(f'{nll=}')\n",
    "print(f'{nll/n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e907cf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". j\n",
      "j a\n",
      "a y\n",
      "y a\n",
      "a n\n",
      "n t\n",
      "t .\n"
     ]
    }
   ],
   "source": [
    "xs,ys=[],[]\n",
    "for w in ['jayant']:\n",
    "    chs=['.']+list(w)+['.']\n",
    "    for ch1, ch2 in zip(chs,chs[1:]):\n",
    "        ix1=stoi[ch1]\n",
    "        ix2=stoi[ch2]\n",
    "        print(ch1,ch2)\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "xs=torch.tensor(xs)\n",
    "ys=torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f637dab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10,  1, 25,  1, 14, 20])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "252df52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10,  1, 25,  1, 14, 20,  0])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b24bff0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "xenc=F.one_hot(xs,num_classes=27).float()\n",
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5042330e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 27])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ce483747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0697e+00, -3.2445e-01,  1.4161e+00, -4.7357e-01, -8.8961e-01,\n",
       "          1.5085e-01,  1.2570e+00, -2.3712e-01, -7.1645e-01,  5.6363e-01,\n",
       "          4.4379e-01,  1.2047e+00,  8.2102e-01,  4.2101e-01, -4.0262e-01,\n",
       "         -4.6120e-01, -2.6149e-01, -1.2943e-01,  3.2679e-01,  3.1930e-01,\n",
       "         -5.7461e-01,  4.1392e-01,  7.8171e-01, -1.5275e+00,  3.7455e-01,\n",
       "         -5.6506e-01,  5.5935e-02],\n",
       "        [-2.8244e-01, -7.7824e-01, -2.9617e-02,  4.7092e-01,  2.7717e-01,\n",
       "         -4.8962e-01,  1.6472e+00, -1.3033e+00, -1.0559e-02,  3.3616e-03,\n",
       "         -1.7322e+00,  1.5175e+00,  6.8383e-01, -8.8821e-01,  3.9723e-01,\n",
       "         -6.9486e-01,  6.6872e-01, -1.5828e+00,  1.4511e-01, -1.9601e-01,\n",
       "          1.0877e-01,  2.0652e+00,  6.0081e-01, -1.2854e+00, -2.6462e-01,\n",
       "         -1.7216e+00,  1.0287e+00],\n",
       "        [-1.2363e+00,  5.4145e-01,  1.3587e+00, -5.8785e-01,  4.2655e-01,\n",
       "         -1.2069e+00,  1.5950e-01, -4.0087e-01, -4.3967e-01,  3.3466e-01,\n",
       "         -3.0213e+00,  1.0181e+00, -9.0119e-01,  1.3893e-01,  1.2044e+00,\n",
       "          1.5102e+00, -9.3797e-01,  1.3916e+00, -3.3371e-01,  1.2830e+00,\n",
       "         -1.3006e+00,  5.6029e-01,  1.5389e+00,  8.8101e-01, -8.3995e-02,\n",
       "          6.6454e-01, -7.4124e-01],\n",
       "        [-7.8824e-01,  2.2198e+00, -1.2601e+00,  9.7037e-01,  1.8456e+00,\n",
       "          9.3038e-01,  5.8023e-01,  6.7509e-02,  1.1169e+00, -5.4328e-01,\n",
       "         -6.0476e-01, -9.1720e-01, -1.6878e+00,  1.5950e+00, -3.9048e-01,\n",
       "         -5.3098e-01, -9.3813e-01,  8.0205e-01,  1.2737e+00,  6.4912e-01,\n",
       "         -3.9108e-02, -3.2815e-01, -5.5952e-01, -1.8242e-01,  5.2089e-01,\n",
       "          4.7630e-01, -1.2968e+00],\n",
       "        [ 1.3193e-01, -7.6143e-02,  2.2118e-01, -1.0208e+00, -4.7455e-01,\n",
       "          5.9526e-01, -7.6626e-01, -5.4749e-01, -1.0016e-01, -4.0323e-01,\n",
       "         -9.5973e-01, -5.6795e-01, -8.6706e-01, -2.3250e-01,  6.4492e-02,\n",
       "          1.6672e-01,  7.2367e-02, -1.0252e-01,  3.0950e-01,  1.1119e+00,\n",
       "          2.3988e-01,  7.9166e-02,  8.4942e-01, -6.3098e-01,  5.9736e-01,\n",
       "         -8.8637e-01, -3.2361e-01],\n",
       "        [ 5.7938e-01, -5.9870e-01,  8.5527e-01, -8.2376e-01, -1.3821e+00,\n",
       "         -8.7074e-01,  1.7482e+00, -4.3232e-01, -8.1715e-01, -1.1440e+00,\n",
       "          5.7979e-01,  1.3917e+00,  6.1708e-01,  1.8553e-01, -1.1524e+00,\n",
       "          7.3763e-01,  1.6990e+00, -5.5930e-01,  1.5730e-02,  1.1767e+00,\n",
       "         -2.4611e-01,  1.9820e+00,  2.0943e+00,  1.2616e+00, -9.3129e-01,\n",
       "         -1.9391e-01, -1.5259e+00],\n",
       "        [ 2.9332e-01, -8.1499e-01, -2.3223e+00, -7.7963e-01, -2.3027e+00,\n",
       "          8.6206e-01,  8.5381e-01,  2.4663e-01, -1.3998e+00,  6.9913e-01,\n",
       "          4.9768e-01,  3.8980e-01, -1.0207e+00, -6.8344e-01, -7.4241e-02,\n",
       "          9.2223e-01,  1.5739e-01,  4.5785e-01,  1.6182e-01, -9.0977e-01,\n",
       "          8.9267e-01, -8.2482e-03,  3.5476e-01, -7.4002e-01, -1.7617e+00,\n",
       "          5.1449e-01, -1.0037e-01],\n",
       "        [ 5.0862e-01, -1.1543e+00,  2.5750e-01, -1.1303e+00,  1.4632e+00,\n",
       "         -5.7763e-01, -4.1534e-01, -2.8198e-01,  7.5047e-01,  4.1300e-01,\n",
       "          6.9300e-01,  1.0712e+00, -7.2151e-01,  5.2370e-01,  9.7385e-01,\n",
       "         -8.9574e-01,  1.0896e+00, -1.4155e-01, -9.9199e-01,  1.3802e+00,\n",
       "          7.5146e-03, -2.2549e+00, -2.4524e+00,  2.7005e+00,  8.9421e-01,\n",
       "          4.7937e-01,  3.6161e-01],\n",
       "        [-1.7410e+00,  1.1776e+00,  8.3957e-01,  1.6217e+00,  1.2385e+00,\n",
       "         -2.2424e-01, -1.0012e+00,  1.5577e-01,  4.3344e-01,  2.5763e+00,\n",
       "          1.5374e+00,  2.7869e-01,  1.0811e+00,  3.2137e-01,  1.1001e+00,\n",
       "          2.1804e+00,  1.5584e+00, -9.2553e-01, -1.7042e-01,  1.6804e+00,\n",
       "          2.3934e-01,  9.3263e-01, -1.7041e+00,  4.7802e-01, -1.8213e+00,\n",
       "          1.9996e+00,  9.4218e-01],\n",
       "        [ 1.1912e+00, -1.5388e-01,  7.2013e-01,  1.1061e+00, -7.2128e-01,\n",
       "          4.0604e-01,  1.3243e+00, -5.9728e-01, -4.6072e-01,  2.3434e-01,\n",
       "         -6.6920e-01, -3.8524e-01, -1.2351e+00,  6.7414e-01,  1.8617e+00,\n",
       "          9.1724e-01, -1.1625e-01,  3.9584e-01, -2.5300e-01,  6.3979e-01,\n",
       "          1.4085e+00,  1.2564e-02, -4.2139e-01,  3.9483e-01,  4.4191e-01,\n",
       "          8.1937e-01,  1.1223e+00],\n",
       "        [-3.3941e-01,  4.4658e-01,  9.0230e-01, -4.6563e-01, -1.0840e-01,\n",
       "          5.9585e-01, -9.5186e-01,  2.2865e+00, -1.3106e-01, -3.0576e-01,\n",
       "          3.6393e-01,  7.1356e-01, -1.3469e+00, -1.7574e-01, -3.8352e-01,\n",
       "          1.7461e-01,  1.2338e+00, -9.8934e-01,  3.2004e-01,  1.0993e+00,\n",
       "         -2.3033e+00, -1.9950e+00,  1.1160e+00, -1.0906e+00, -7.4587e-01,\n",
       "         -2.9333e+00, -4.3243e-01],\n",
       "        [ 2.0487e-02, -6.9488e-01,  5.9380e-01,  1.1902e-02, -2.2058e-01,\n",
       "          8.5325e-01,  1.0624e+00,  6.1468e-01,  3.4526e-01,  4.6313e-01,\n",
       "          3.1298e-01, -9.1774e-01, -2.8315e+00, -1.7777e+00, -7.4626e-01,\n",
       "         -1.0243e+00, -1.9855e+00, -1.7364e+00,  6.1490e-02, -4.5502e-01,\n",
       "          1.3330e-01, -6.8047e-01, -1.8958e+00,  7.0634e-03, -1.0022e+00,\n",
       "          1.4356e+00, -2.9178e-01],\n",
       "        [-1.1271e-01, -7.3998e-01,  5.8160e-01,  2.7091e+00,  1.0225e+00,\n",
       "         -1.2269e+00, -2.2126e-01, -4.2790e-01, -2.7664e-01, -1.4632e+00,\n",
       "          1.1388e+00, -1.2021e+00,  1.2695e+00,  2.8518e-01, -1.8521e-01,\n",
       "         -1.0163e+00, -1.0078e+00,  9.9924e-01,  9.0456e-01,  4.8471e-01,\n",
       "         -9.5869e-01, -3.1019e-01, -1.5539e+00, -1.0809e+00,  5.5257e-01,\n",
       "          7.3497e-01, -6.3670e-01],\n",
       "        [ 1.6075e+00,  6.3238e-01,  1.7973e+00, -6.4207e-01, -4.3485e-01,\n",
       "         -5.3665e-01, -2.4505e-01, -8.6897e-01,  1.8020e-01,  6.0426e-01,\n",
       "          1.8226e+00, -1.8786e+00,  1.4282e+00, -9.0269e-01, -6.7215e-01,\n",
       "         -8.1293e-01, -1.0966e+00, -3.2239e-01, -8.3709e-01,  1.3576e+00,\n",
       "         -1.5034e+00, -9.8566e-01, -3.0029e-01, -6.4063e-01,  1.2001e+00,\n",
       "         -1.0781e+00,  1.1987e-01],\n",
       "        [ 4.2593e-01, -4.4054e-01,  3.6319e-01, -1.0139e+00,  7.2325e-01,\n",
       "          1.4883e+00, -8.2978e-01, -9.0734e-01,  4.7346e-01,  1.2477e+00,\n",
       "         -3.6834e-02,  2.8049e-01, -8.2230e-01,  1.3162e+00,  4.6285e-01,\n",
       "          9.8244e-01,  1.1642e+00,  3.4145e-01, -5.3796e-02, -1.3926e+00,\n",
       "         -7.9579e-01, -1.1550e+00,  1.0180e+00, -8.0107e-01, -3.8150e-01,\n",
       "          1.0602e+00, -9.0366e-01],\n",
       "        [ 2.1458e-01,  4.8028e-03,  4.2893e-01, -1.3330e+00,  7.1928e-01,\n",
       "         -6.8904e-01, -1.0986e+00,  5.8972e-02, -1.3625e+00,  5.0143e-01,\n",
       "         -1.3339e+00,  6.6528e-01, -3.4481e-01, -7.0382e-01, -5.8268e-01,\n",
       "         -6.9737e-01,  5.9903e-01,  1.5023e+00,  5.4758e-01, -8.9981e-01,\n",
       "          6.0942e-01,  9.5889e-01, -1.1572e+00,  6.7352e-01, -1.8716e-01,\n",
       "         -1.3614e-01, -5.9513e-01],\n",
       "        [ 2.5479e+00,  9.9708e-01, -4.6573e-01, -3.6504e-01,  1.8065e+00,\n",
       "         -9.2347e-02,  1.2089e+00, -1.4519e+00, -2.4564e-01, -8.7091e-01,\n",
       "         -1.0344e+00, -2.7484e+00,  1.7275e+00, -1.6492e+00,  3.2416e-01,\n",
       "         -1.0588e+00,  9.1145e-01, -9.8419e-01,  5.0236e-01,  3.3814e+00,\n",
       "          4.0025e-01, -6.6587e-02,  4.8128e-01, -4.9155e-01, -1.0081e+00,\n",
       "         -5.7262e-01, -7.5160e-01],\n",
       "        [-2.3885e+00,  8.0238e-01,  7.2533e-01,  8.9940e-01,  3.3066e-01,\n",
       "         -3.5542e-01,  2.1053e+00,  4.5303e-01,  2.4374e+00,  5.4056e-01,\n",
       "         -3.5189e-01, -6.5133e-01, -8.7335e-01, -1.9578e+00,  6.4651e-01,\n",
       "          2.2603e+00,  4.6913e-01, -4.1648e-01,  1.1013e+00, -4.7927e-01,\n",
       "         -4.6305e-01, -2.2314e-01,  1.0042e+00,  6.5120e-01, -4.8155e-01,\n",
       "         -2.6934e-01, -1.5329e+00],\n",
       "        [ 5.9527e-01, -6.3060e-01,  1.8365e+00,  7.9852e-02,  1.7119e-01,\n",
       "          8.7229e-01, -2.7781e+00,  1.3004e+00, -1.0552e-01, -2.4200e+00,\n",
       "          1.7503e-01, -1.3717e+00, -1.9979e+00,  9.5425e-01, -1.4815e+00,\n",
       "          7.3201e-01,  9.4181e-01,  5.6168e-01, -5.1674e-01,  9.6762e-01,\n",
       "         -3.8259e-01,  2.5058e+00, -8.9554e-01, -2.4909e-01,  1.5025e+00,\n",
       "          7.3512e-02, -2.7052e-01],\n",
       "        [-1.0396e+00, -1.7948e+00, -8.1757e-01, -2.5389e+00, -1.0779e+00,\n",
       "          1.0502e+00, -3.5393e-01,  7.7164e-01,  1.7232e-01,  3.9995e-01,\n",
       "          9.3624e-01,  6.6238e-01,  2.2380e-01, -3.2975e-01,  1.9761e-01,\n",
       "         -5.5579e-01, -6.3343e-01,  1.4922e+00, -7.1895e-03,  1.0978e+00,\n",
       "          4.0939e-01,  5.7720e-01, -9.2191e-02, -2.3198e-01, -6.3465e-01,\n",
       "          8.9389e-02, -1.0560e+00],\n",
       "        [ 1.0413e-02,  3.3807e-01,  8.0019e-01,  1.0638e+00,  5.9630e-01,\n",
       "         -1.5388e-01,  9.6577e-01,  1.9695e+00, -9.2968e-01,  1.4947e+00,\n",
       "         -1.7598e-01,  8.0270e-01,  1.8860e-01,  6.9880e-01, -9.9424e-01,\n",
       "          4.8906e-02,  5.4123e-01,  9.1912e-01,  4.4345e-01,  4.8374e-02,\n",
       "         -2.9865e-01,  4.4203e-01, -4.0636e-01, -1.4683e+00,  8.8049e-01,\n",
       "         -6.8498e-01, -1.6693e+00],\n",
       "        [ 1.8087e-01, -6.4170e-01,  1.6800e-01,  2.9866e-01, -4.3816e-01,\n",
       "          1.4586e+00,  1.5162e+00,  1.0373e+00,  1.3446e+00, -9.1448e-01,\n",
       "         -1.6433e+00, -2.9925e-01,  4.7145e-02,  1.7933e+00,  1.1672e-01,\n",
       "         -6.2233e-01, -2.6312e-01, -2.3877e+00, -4.2292e-01,  6.8012e-02,\n",
       "          2.0672e+00,  9.7032e-01, -1.5782e+00, -2.2932e-01,  7.3806e-01,\n",
       "         -1.2560e+00,  8.1571e-01],\n",
       "        [ 4.9582e-01,  1.9371e+00, -6.5443e-02,  2.6138e-01,  7.9751e-01,\n",
       "          9.2064e-01, -5.6817e-01, -1.4782e+00, -1.1019e+00,  9.7964e-01,\n",
       "          2.3701e-01, -2.2000e+00,  1.5569e+00, -7.3183e-01,  1.9375e-01,\n",
       "          1.8917e+00, -3.1299e-02, -4.9545e-02,  1.7589e-01, -2.6250e-01,\n",
       "          1.3284e+00, -3.9795e-01, -7.5111e-01,  6.6858e-01,  5.0692e-01,\n",
       "         -1.8696e+00,  1.6250e+00],\n",
       "        [-8.7277e-01,  1.4376e+00,  7.7229e-01, -1.5630e+00, -3.1302e-02,\n",
       "          7.0371e-01,  7.3244e-01,  1.4931e+00,  2.1733e-01, -2.5536e-01,\n",
       "         -1.3338e-01,  1.7986e-02,  4.3651e-01, -9.6303e-01,  4.1017e-01,\n",
       "         -4.8927e-01,  7.4724e-01,  4.0218e-01, -1.2056e+00, -1.6268e-01,\n",
       "         -1.5867e-02, -6.4830e-01,  6.4153e-01,  1.7286e-01, -1.8989e+00,\n",
       "          4.0118e-01, -1.4748e+00],\n",
       "        [-2.3956e-01, -1.5662e-01,  2.1640e+00, -1.8046e-01, -2.0089e-01,\n",
       "          1.1212e+00, -1.0094e+00,  1.1085e+00, -1.7540e+00, -6.9034e-01,\n",
       "         -5.5601e-01, -5.8893e-02,  4.1586e-01,  6.0190e-01, -1.6277e-02,\n",
       "          1.3763e+00, -3.6596e-01, -1.1719e+00,  1.4311e+00,  2.5704e-01,\n",
       "         -9.7578e-01, -5.3560e-01,  9.0945e-01,  1.1630e+00,  4.0523e-01,\n",
       "          1.0726e+00, -3.7202e-01],\n",
       "        [ 6.2334e-01, -1.0611e+00,  2.2469e+00,  9.1709e-01, -4.5693e-01,\n",
       "          6.1629e-01,  4.8499e-01, -6.0394e-01, -6.3067e-01,  6.5884e-01,\n",
       "         -1.2014e+00,  1.0796e-01,  8.5724e-01,  4.7136e-01,  2.8256e-01,\n",
       "          2.2576e+00, -8.4041e-01, -4.2797e-01,  2.1261e-01, -3.2439e-01,\n",
       "         -1.4725e+00, -3.1540e-01,  7.3996e-01,  1.4254e-01, -1.4680e-01,\n",
       "          2.1905e+00,  3.7453e-01],\n",
       "        [ 1.4434e-01,  5.4491e-01,  2.2530e-01, -1.6845e+00, -2.5521e-02,\n",
       "          2.6996e-01,  5.4437e-01, -8.5037e-02, -1.9338e-01,  2.7448e-01,\n",
       "          1.9138e+00, -1.0630e+00,  8.2727e-01,  1.1717e+00, -1.6671e-01,\n",
       "         -1.9854e-01,  1.9428e-01,  2.6521e-01, -8.9289e-01,  1.5715e-01,\n",
       "         -7.6988e-01,  1.5407e+00, -1.0746e+00,  1.1147e+00,  1.1534e+00,\n",
       "          1.7665e-01, -6.7199e-01]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W=torch.randn((27,27))\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f9dac3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0697, -0.3245,  1.4161, -0.4736, -0.8896,  0.1508,  1.2570, -0.2371,\n",
       "         -0.7165,  0.5636,  0.4438,  1.2047,  0.8210,  0.4210, -0.4026, -0.4612,\n",
       "         -0.2615, -0.1294,  0.3268,  0.3193, -0.5746,  0.4139,  0.7817, -1.5275,\n",
       "          0.3745, -0.5651,  0.0559],\n",
       "        [-0.3394,  0.4466,  0.9023, -0.4656, -0.1084,  0.5958, -0.9519,  2.2865,\n",
       "         -0.1311, -0.3058,  0.3639,  0.7136, -1.3469, -0.1757, -0.3835,  0.1746,\n",
       "          1.2338, -0.9893,  0.3200,  1.0993, -2.3033, -1.9950,  1.1160, -1.0906,\n",
       "         -0.7459, -2.9333, -0.4324],\n",
       "        [-0.2824, -0.7782, -0.0296,  0.4709,  0.2772, -0.4896,  1.6472, -1.3033,\n",
       "         -0.0106,  0.0034, -1.7322,  1.5175,  0.6838, -0.8882,  0.3972, -0.6949,\n",
       "          0.6687, -1.5828,  0.1451, -0.1960,  0.1088,  2.0652,  0.6008, -1.2854,\n",
       "         -0.2646, -1.7216,  1.0287],\n",
       "        [ 0.6233, -1.0611,  2.2469,  0.9171, -0.4569,  0.6163,  0.4850, -0.6039,\n",
       "         -0.6307,  0.6588, -1.2014,  0.1080,  0.8572,  0.4714,  0.2826,  2.2576,\n",
       "         -0.8404, -0.4280,  0.2126, -0.3244, -1.4725, -0.3154,  0.7400,  0.1425,\n",
       "         -0.1468,  2.1905,  0.3745],\n",
       "        [-0.2824, -0.7782, -0.0296,  0.4709,  0.2772, -0.4896,  1.6472, -1.3033,\n",
       "         -0.0106,  0.0034, -1.7322,  1.5175,  0.6838, -0.8882,  0.3972, -0.6949,\n",
       "          0.6687, -1.5828,  0.1451, -0.1960,  0.1088,  2.0652,  0.6008, -1.2854,\n",
       "         -0.2646, -1.7216,  1.0287],\n",
       "        [ 0.4259, -0.4405,  0.3632, -1.0139,  0.7233,  1.4883, -0.8298, -0.9073,\n",
       "          0.4735,  1.2477, -0.0368,  0.2805, -0.8223,  1.3162,  0.4628,  0.9824,\n",
       "          1.1642,  0.3414, -0.0538, -1.3926, -0.7958, -1.1550,  1.0180, -0.8011,\n",
       "         -0.3815,  1.0602, -0.9037],\n",
       "        [ 0.0104,  0.3381,  0.8002,  1.0638,  0.5963, -0.1539,  0.9658,  1.9695,\n",
       "         -0.9297,  1.4947, -0.1760,  0.8027,  0.1886,  0.6988, -0.9942,  0.0489,\n",
       "          0.5412,  0.9191,  0.4434,  0.0484, -0.2986,  0.4420, -0.4064, -1.4683,\n",
       "          0.8805, -0.6850, -1.6693]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = xenc @ W\n",
    "# @ is matrix multiplication operator in pytorch\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6d4a019d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1262, 0.7229, 4.1211, 0.6228, 0.4108, 1.1628, 3.5149, 0.7889, 0.4885,\n",
       "         1.7570, 1.5586, 3.3356, 2.2728, 1.5235, 0.6686, 0.6305, 0.7699, 0.8786,\n",
       "         1.3865, 1.3762, 0.5629, 1.5127, 2.1852, 0.2171, 1.4543, 0.5683, 1.0575],\n",
       "        [0.7122, 1.5630, 2.4653, 0.6277, 0.8973, 1.8146, 0.3860, 9.8400, 0.8772,\n",
       "         0.7366, 1.4390, 2.0413, 0.2600, 0.8388, 0.6815, 1.1908, 3.4342, 0.3718,\n",
       "         1.3772, 3.0020, 0.0999, 0.1360, 3.0526, 0.3360, 0.4743, 0.0532, 0.6489],\n",
       "        [0.7539, 0.4592, 0.9708, 1.6015, 1.3194, 0.6129, 5.1922, 0.2716, 0.9895,\n",
       "         1.0034, 0.1769, 4.5609, 1.9814, 0.4114, 1.4877, 0.4991, 1.9517, 0.2054,\n",
       "         1.1562, 0.8220, 1.1149, 7.8872, 1.8236, 0.2765, 0.7675, 0.1788, 2.7973],\n",
       "        [1.8652, 0.3461, 9.4580, 2.5020, 0.6332, 1.8520, 1.6242, 0.5467, 0.5322,\n",
       "         1.9326, 0.3008, 1.1140, 2.3566, 1.6022, 1.3265, 9.5604, 0.4315, 0.6518,\n",
       "         1.2369, 0.7230, 0.2293, 0.7295, 2.0959, 1.1532, 0.8635, 8.9395, 1.4543],\n",
       "        [0.7539, 0.4592, 0.9708, 1.6015, 1.3194, 0.6129, 5.1922, 0.2716, 0.9895,\n",
       "         1.0034, 0.1769, 4.5609, 1.9814, 0.4114, 1.4877, 0.4991, 1.9517, 0.2054,\n",
       "         1.1562, 0.8220, 1.1149, 7.8872, 1.8236, 0.2765, 0.7675, 0.1788, 2.7973],\n",
       "        [1.5310, 0.6437, 1.4379, 0.3628, 2.0611, 4.4298, 0.4361, 0.4036, 1.6055,\n",
       "         3.4825, 0.9638, 1.3238, 0.4394, 3.7294, 1.5886, 2.6710, 3.2032, 1.4070,\n",
       "         0.9476, 0.2484, 0.4512, 0.3151, 2.7677, 0.4488, 0.6828, 2.8870, 0.4051],\n",
       "        [1.0105, 1.4022, 2.2260, 2.8973, 1.8154, 0.8574, 2.6268, 7.1669, 0.3947,\n",
       "         4.4581, 0.8386, 2.2316, 1.2076, 2.0113, 0.3700, 1.0501, 1.7181, 2.5071,\n",
       "         1.5581, 1.0496, 0.7418, 1.5559, 0.6661, 0.2303, 2.4121, 0.5041, 0.1884]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts=(xenc @ W).exp()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6b24f1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 27])\n",
      "torch.Size([7, 1])\n",
      "torch.Size([7, 27])\n",
      "tensor([[0.0035, 0.0203, 0.1155, 0.0175, 0.0115, 0.0326, 0.0985, 0.0221, 0.0137,\n",
      "         0.0493, 0.0437, 0.0935, 0.0637, 0.0427, 0.0187, 0.0177, 0.0216, 0.0246,\n",
      "         0.0389, 0.0386, 0.0158, 0.0424, 0.0613, 0.0061, 0.0408, 0.0159, 0.0296],\n",
      "        [0.0181, 0.0397, 0.0626, 0.0159, 0.0228, 0.0461, 0.0098, 0.2500, 0.0223,\n",
      "         0.0187, 0.0366, 0.0519, 0.0066, 0.0213, 0.0173, 0.0303, 0.0873, 0.0094,\n",
      "         0.0350, 0.0763, 0.0025, 0.0035, 0.0776, 0.0085, 0.0121, 0.0014, 0.0165],\n",
      "        [0.0183, 0.0111, 0.0235, 0.0388, 0.0320, 0.0148, 0.1258, 0.0066, 0.0240,\n",
      "         0.0243, 0.0043, 0.1105, 0.0480, 0.0100, 0.0360, 0.0121, 0.0473, 0.0050,\n",
      "         0.0280, 0.0199, 0.0270, 0.1911, 0.0442, 0.0067, 0.0186, 0.0043, 0.0678],\n",
      "        [0.0333, 0.0062, 0.1687, 0.0446, 0.0113, 0.0330, 0.0290, 0.0098, 0.0095,\n",
      "         0.0345, 0.0054, 0.0199, 0.0420, 0.0286, 0.0237, 0.1705, 0.0077, 0.0116,\n",
      "         0.0221, 0.0129, 0.0041, 0.0130, 0.0374, 0.0206, 0.0154, 0.1595, 0.0259],\n",
      "        [0.0183, 0.0111, 0.0235, 0.0388, 0.0320, 0.0148, 0.1258, 0.0066, 0.0240,\n",
      "         0.0243, 0.0043, 0.1105, 0.0480, 0.0100, 0.0360, 0.0121, 0.0473, 0.0050,\n",
      "         0.0280, 0.0199, 0.0270, 0.1911, 0.0442, 0.0067, 0.0186, 0.0043, 0.0678],\n",
      "        [0.0375, 0.0157, 0.0352, 0.0089, 0.0504, 0.1084, 0.0107, 0.0099, 0.0393,\n",
      "         0.0852, 0.0236, 0.0324, 0.0108, 0.0912, 0.0389, 0.0653, 0.0784, 0.0344,\n",
      "         0.0232, 0.0061, 0.0110, 0.0077, 0.0677, 0.0110, 0.0167, 0.0706, 0.0099],\n",
      "        [0.0221, 0.0307, 0.0487, 0.0634, 0.0397, 0.0188, 0.0575, 0.1568, 0.0086,\n",
      "         0.0976, 0.0184, 0.0488, 0.0264, 0.0440, 0.0081, 0.0230, 0.0376, 0.0549,\n",
      "         0.0341, 0.0230, 0.0162, 0.0340, 0.0146, 0.0050, 0.0528, 0.0110, 0.0041]])\n"
     ]
    }
   ],
   "source": [
    "probs = counts/counts.sum(1,keepdims= True)\n",
    "print(counts.shape)\n",
    "print(counts.sum(1,keepdims= True).shape)\n",
    "print(probs.shape)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2305051b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ae2de928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10,  1, 25,  1, 14, 20])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5853e620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10,  1, 25,  1, 14, 20,  0])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "81d19d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly initialize 27 neurons weights each neuron recieves 27 inputs\n",
    "g=torch.Generator().manual_seed(2147483647)\n",
    "W=torch.randn((27,27),generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "627ae2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward pass\n",
    "xenc=F.one_hot(xs,num_classes=27).float() #input to network:one_hot encoding\n",
    "logits=xenc@W #predict log counts\n",
    "counts=logits.exp() #counts, equivalent to N\n",
    "probs = counts / counts.sum(1,keepdims=True) #probabilities\n",
    "loss=-probs[torch.arange(7),ys].log().mean()+ 0.01*(W**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "286ddac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.64088773727417\n"
     ]
    }
   ],
   "source": [
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "cddaba1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "# create the dataset\n",
    "xs, ys = [], []\n",
    "for w in words:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1, ch2 in zip(chs, chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# initialize the 'network'\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "280be1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.529768228530884\n",
      "2.527860164642334\n",
      "2.5260636806488037\n",
      "2.5243701934814453\n",
      "2.522773265838623\n",
      "2.52126407623291\n",
      "2.519836664199829\n",
      "2.5184857845306396\n",
      "2.5172054767608643\n",
      "2.515990734100342\n",
      "2.5148372650146484\n",
      "2.5137410163879395\n",
      "2.51269793510437\n",
      "2.511704921722412\n",
      "2.5107579231262207\n",
      "2.509855031967163\n",
      "2.5089924335479736\n",
      "2.5081686973571777\n",
      "2.507380485534668\n",
      "2.5066256523132324\n",
      "2.5059030055999756\n",
      "2.5052106380462646\n",
      "2.5045459270477295\n",
      "2.5039076805114746\n",
      "2.503295421600342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.7402e-04, -7.3854e-06, -8.3105e-06, -8.0962e-06, -7.9986e-06,\n",
       "         -8.1088e-06, -2.7070e-05, -9.8294e-06, -9.0726e-06, -1.0086e-05,\n",
       "         -7.6907e-06, -7.5704e-06, -8.0741e-06, -7.6623e-06, -8.5095e-06,\n",
       "         -6.6660e-06, -9.8740e-06,  2.6821e-07, -8.0300e-06, -7.8175e-06,\n",
       "         -8.3101e-06,  1.1569e-04, -3.1048e-05, -1.3829e-06,  6.0310e-05,\n",
       "         -9.9011e-06, -8.9174e-06],\n",
       "        [-2.2677e-05, -3.2262e-05, -3.0407e-05, -3.5297e-05, -2.5764e-05,\n",
       "         -2.8351e-05,  5.4357e-05, -2.7544e-06, -2.3613e-05, -2.4267e-05,\n",
       "          2.3182e-05, -3.1849e-05, -2.3493e-05, -2.4290e-05, -2.2792e-05,\n",
       "          1.1495e-04,  1.0372e-04,  7.2446e-05, -2.3185e-05, -2.5466e-05,\n",
       "         -2.8366e-05, -3.1260e-05, -2.7111e-05,  2.4022e-05,  1.7283e-05,\n",
       "         -2.3821e-05, -3.7771e-05],\n",
       "        [-1.3662e-04, -3.6481e-04,  3.3176e-05,  1.3524e-04, -1.5973e-04,\n",
       "         -1.3712e-04,  1.1335e-04,  8.7450e-05, -1.0283e-04, -5.2377e-04,\n",
       "          1.6620e-04,  3.9541e-05,  4.0844e-06,  2.2258e-04,  2.8185e-05,\n",
       "         -8.1221e-05,  1.4799e-04,  1.9977e-04, -1.2107e-04,  2.9048e-05,\n",
       "          4.3900e-05,  1.0666e-04,  1.1633e-04,  1.7218e-04,  5.7103e-05,\n",
       "         -9.2595e-05,  2.1447e-05],\n",
       "        [ 2.7928e-05, -1.0689e-04,  3.8924e-05,  1.2332e-04,  1.6313e-04,\n",
       "         -1.1180e-04,  7.6985e-05,  4.0435e-05, -1.0901e-04, -3.2108e-04,\n",
       "          1.4620e-04, -1.4110e-04, -2.8135e-04,  8.7603e-05,  2.0905e-04,\n",
       "         -1.8985e-04,  1.1857e-04,  3.7247e-06, -1.1513e-05,  4.9764e-05,\n",
       "         -1.7750e-05, -1.2887e-04,  1.2414e-04,  1.4496e-05,  1.1003e-04,\n",
       "         -2.9582e-04,  6.7112e-05],\n",
       "        [-1.9978e-04, -1.5301e-04,  1.1009e-04,  1.6653e-04, -1.0780e-04,\n",
       "         -1.5316e-04,  8.9001e-05,  6.7327e-05, -3.3495e-04, -1.6296e-04,\n",
       "          1.6469e-04,  1.8759e-04, -3.1582e-05,  6.5966e-05,  6.3628e-05,\n",
       "         -3.3708e-04,  9.6913e-05,  1.7407e-04, -2.3426e-04,  4.1954e-05,\n",
       "          1.6490e-04,  7.9782e-07,  8.5659e-05,  7.1247e-05,  2.7373e-05,\n",
       "         -3.1746e-04,  1.6494e-04],\n",
       "        [-1.3398e-05, -2.0812e-05,  3.7766e-05,  3.0201e-05, -2.5370e-05,\n",
       "         -1.5875e-05,  2.1965e-05,  4.3905e-05, -3.9618e-05, -1.8774e-05,\n",
       "          1.4726e-04, -5.8987e-06, -1.3622e-05, -1.9504e-05, -1.3896e-05,\n",
       "         -2.5245e-05,  8.6037e-05,  7.7563e-05, -1.4494e-05, -1.8311e-05,\n",
       "         -2.3194e-05,  1.0634e-04, -2.6537e-05, -5.8473e-05, -1.1478e-05,\n",
       "         -1.6771e-05,  1.0432e-05],\n",
       "        [-3.3692e-05, -3.3003e-04,  2.6880e-04,  3.2695e-05,  1.0502e-04,\n",
       "         -2.2617e-04, -1.0479e-04,  9.6829e-06,  1.8700e-04, -2.1273e-04,\n",
       "          1.2728e-04,  6.7762e-05, -3.3591e-05,  3.4101e-05, -1.0447e-05,\n",
       "         -1.2500e-04,  2.0246e-04,  5.7310e-05, -8.0784e-05, -5.0927e-06,\n",
       "         -7.9915e-05,  7.3128e-05,  2.9559e-05,  4.1033e-05,  9.4679e-05,\n",
       "          7.7646e-05,  9.3139e-05],\n",
       "        [-2.9464e-04, -2.0280e-04,  1.4745e-04,  1.4043e-04,  2.0356e-04,\n",
       "         -2.0406e-04,  4.6976e-05,  7.1167e-05, -3.1404e-04, -2.7050e-04,\n",
       "          6.3676e-05,  2.1022e-04,  1.5038e-04,  1.8624e-04,  1.2899e-04,\n",
       "         -2.3498e-04,  1.7330e-04,  1.7905e-04, -3.2845e-04,  8.6532e-05,\n",
       "         -9.9679e-05, -1.1713e-04,  1.8164e-04,  3.5127e-05,  3.8937e-05,\n",
       "         -1.7331e-05,  5.1273e-05],\n",
       "        [-7.6500e-05, -7.6714e-05,  1.8183e-04,  1.5459e-04,  1.4882e-04,\n",
       "         -9.4409e-05,  7.1683e-05,  1.4592e-04,  8.3894e-05, -8.8087e-05,\n",
       "          1.8812e-05,  1.3398e-04, -3.9754e-04, -1.3770e-04, -2.4042e-04,\n",
       "         -1.6086e-04,  1.1672e-04,  1.9604e-04, -2.2379e-04,  1.0480e-04,\n",
       "          2.3940e-05, -4.1488e-05,  1.3010e-05,  1.1348e-04,  1.6963e-04,\n",
       "         -1.0218e-04, -4.2555e-05],\n",
       "        [-3.7063e-05, -3.7102e-05,  2.8312e-05, -4.7351e-05, -4.6501e-05,\n",
       "         -3.8159e-05,  3.1664e-05, -6.6409e-05,  6.1613e-05,  7.8661e-05,\n",
       "          6.3430e-05, -5.2226e-05, -3.8953e-05, -7.2478e-05, -3.7425e-05,\n",
       "         -5.0395e-05,  1.4605e-04,  1.4750e-04, -4.1721e-05, -3.9048e-05,\n",
       "         -4.6699e-05,  5.0797e-05, -3.8300e-05,  1.4415e-04,  5.5745e-05,\n",
       "         -4.2484e-05, -7.1936e-05],\n",
       "        [-9.6306e-05, -1.5942e-04,  1.3133e-04,  1.7201e-05,  4.4235e-05,\n",
       "         -2.8740e-04,  2.3171e-05,  7.2351e-05, -1.6569e-04, -1.2236e-04,\n",
       "          7.3375e-05,  8.2888e-05,  1.1325e-05,  1.4123e-04,  2.6080e-05,\n",
       "         -2.0498e-04,  2.5237e-05,  1.4662e-04, -6.3888e-05,  1.1990e-04,\n",
       "          1.3505e-05, -2.2497e-04,  6.0059e-05,  9.9385e-05,  2.3520e-05,\n",
       "          4.3359e-05,  6.5980e-05],\n",
       "        [-3.1201e-04, -1.4315e-04,  2.6351e-06,  4.1360e-05,  1.8207e-04,\n",
       "         -1.4671e-04,  1.7392e-04,  1.8042e-04, -1.5924e-04, -1.7264e-04,\n",
       "          1.8849e-05,  1.2791e-04, -4.4830e-05,  8.2036e-05,  8.5835e-06,\n",
       "         -1.6284e-04,  1.4279e-04,  1.0604e-04, -7.3060e-05, -4.8182e-05,\n",
       "          1.3610e-04, -3.9541e-05,  1.7113e-04,  5.9161e-05,  1.5337e-04,\n",
       "         -4.9147e-04,  9.2944e-05],\n",
       "        [-8.6865e-05, -8.1419e-05,  4.2831e-05, -1.5894e-05, -1.1100e-04,\n",
       "         -8.0924e-05,  3.5758e-05,  1.3548e-04,  1.0935e-04, -8.1704e-05,\n",
       "          2.0249e-05,  4.5378e-06, -8.6582e-05, -5.2919e-06,  1.2438e-04,\n",
       "         -1.0231e-04,  1.5237e-04,  1.6927e-04,  4.0531e-05, -1.0434e-04,\n",
       "         -3.0506e-05, -1.3553e-04, -7.2861e-06,  1.3699e-04,  1.4593e-04,\n",
       "         -8.4842e-05,  8.9583e-05],\n",
       "        [-1.3798e-04, -1.0322e-04, -6.3441e-05,  1.4963e-05,  1.1590e-04,\n",
       "         -1.1591e-04,  1.2062e-04,  1.1975e-04,  1.8231e-04, -1.0852e-04,\n",
       "          1.3112e-05,  1.7813e-04,  5.9935e-05, -1.6874e-04,  2.5741e-05,\n",
       "         -1.8436e-04,  7.7727e-05,  6.9392e-05, -2.5173e-05, -9.3522e-05,\n",
       "          9.6153e-05, -3.0040e-04,  6.6827e-05,  1.0034e-04,  1.9425e-04,\n",
       "         -1.6122e-04,  3.9621e-05],\n",
       "        [-7.3764e-05, -7.5271e-05,  1.9699e-04, -8.2026e-05, -8.7099e-05,\n",
       "         -7.8863e-05,  8.9879e-05, -1.0315e-04,  9.9299e-05, -7.7388e-05,\n",
       "          2.5838e-05,  5.0545e-05, -1.3400e-04,  1.7042e-04, -7.6891e-05,\n",
       "         -1.0500e-04,  2.0586e-04,  1.3825e-04,  6.3355e-05, -9.1660e-05,\n",
       "         -1.1457e-04, -7.7660e-06,  5.4637e-07,  1.8605e-04,  1.2798e-04,\n",
       "         -1.2370e-04, -1.1282e-04],\n",
       "        [-3.1094e-05,  3.5950e-05, -1.9476e-04,  5.1896e-05, -1.4893e-05,\n",
       "         -1.1163e-04,  1.7492e-04,  1.8151e-04, -6.4002e-05, -6.1555e-06,\n",
       "         -2.6917e-05,  1.2688e-04, -3.3763e-05, -4.3814e-05, -2.7032e-05,\n",
       "         -5.7919e-05,  4.5128e-05,  1.4110e-04, -2.9636e-05, -9.5240e-05,\n",
       "          2.4054e-05, -3.4598e-05, -8.3996e-05, -1.9817e-04,  3.2230e-05,\n",
       "          1.4048e-06,  1.5629e-04],\n",
       "        [-3.2077e-05, -1.5742e-04,  9.1051e-05,  1.5870e-04,  1.1586e-04,\n",
       "         -3.6907e-04,  9.3119e-05,  1.5317e-04, -2.4788e-04, -1.2608e-04,\n",
       "          1.0062e-04,  6.0378e-05,  2.3533e-05,  7.9148e-05, -5.4889e-05,\n",
       "         -3.4895e-05, -3.2310e-06, -3.0897e-05, -3.7271e-04, -9.8954e-06,\n",
       "         -1.2169e-07,  1.6888e-05,  2.1956e-05,  1.9395e-05,  1.9365e-04,\n",
       "          6.1397e-05,  2.4643e-05],\n",
       "        [-3.9859e-06,  6.3354e-06,  5.9644e-05, -5.3044e-05, -2.0362e-05,\n",
       "          2.6053e-06,  5.5462e-05, -1.7959e-05,  3.6510e-05, -1.0119e-04,\n",
       "          1.1880e-05, -4.4349e-06,  7.3900e-05, -2.8149e-05, -2.4449e-05,\n",
       "          7.5014e-05,  1.3117e-04,  6.9780e-05,  1.3026e-04,  3.9841e-05,\n",
       "         -4.8722e-06, -6.9155e-04, -4.6759e-06,  7.0179e-05, -1.1650e-06,\n",
       "          1.5334e-04,  3.1554e-05],\n",
       "        [-3.6739e-05, -3.5564e-05,  9.3337e-05, -3.4415e-05, -1.9217e-05,\n",
       "         -3.6184e-05,  1.6996e-04, -5.7312e-05,  4.7089e-05, -3.5230e-05,\n",
       "          5.9179e-05, -2.0179e-04, -4.8687e-05,  8.3693e-06, -3.1371e-05,\n",
       "         -3.8859e-05,  1.6568e-04,  1.6155e-04, -6.6802e-05, -3.1590e-05,\n",
       "         -8.9258e-05, -1.8307e-04, -2.5184e-04,  1.2236e-04,  9.8306e-05,\n",
       "         -4.0059e-05,  1.9510e-04],\n",
       "        [-9.0833e-05, -9.0553e-05,  1.3497e-04,  8.5119e-05,  8.9778e-05,\n",
       "         -9.4427e-05,  1.0489e-04,  1.0598e-04, -8.9899e-05, -9.9742e-05,\n",
       "          7.4367e-05, -2.0300e-04, -9.6567e-05, -1.4745e-06,  4.0382e-05,\n",
       "         -1.1399e-04,  8.2107e-05,  8.1738e-05,  2.2489e-05, -1.7873e-04,\n",
       "         -9.7005e-05, -6.9690e-05,  7.5147e-05,  9.7727e-05,  1.9114e-04,\n",
       "         -1.0225e-04,  2.0859e-04],\n",
       "        [-1.4065e-04, -1.2551e-04,  1.0357e-04,  8.5267e-05,  2.0706e-04,\n",
       "         -1.3544e-04,  7.5349e-05,  2.1652e-04, -1.4277e-04, -1.4420e-04,\n",
       "          1.5895e-04,  2.1080e-04, -2.5699e-04,  1.3264e-04,  5.4914e-05,\n",
       "         -1.3483e-04,  2.1438e-04,  1.3207e-04, -1.7503e-04,  1.1274e-04,\n",
       "         -1.4817e-04, -4.4266e-05,  1.1805e-04,  1.4759e-04,  1.8502e-04,\n",
       "         -2.7574e-04, -1.4862e-04],\n",
       "        [-1.7457e-05, -1.4696e-04, -3.4889e-04,  1.1572e-04, -1.1805e-04,\n",
       "         -1.5611e-04,  2.5154e-04,  5.6907e-05, -1.0735e-05,  4.8820e-05,\n",
       "          1.1663e-04, -1.8588e-04, -2.2328e-04, -2.5361e-05, -9.4208e-05,\n",
       "          1.7207e-04,  7.4049e-05,  7.9151e-05, -1.0605e-04, -3.4282e-05,\n",
       "          5.0117e-06,  8.7858e-05, -2.1973e-05,  1.1174e-05,  3.7440e-05,\n",
       "          2.4929e-04,  1.7687e-04],\n",
       "        [-8.7441e-05, -2.2495e-04,  1.5710e-04,  2.5932e-05,  5.8796e-05,\n",
       "         -3.1250e-04,  1.2320e-04,  4.7664e-05,  3.0209e-05, -2.0630e-04,\n",
       "          2.0329e-05,  1.0262e-04, -1.0948e-05,  1.7741e-04,  1.1780e-06,\n",
       "         -2.1193e-04,  1.3718e-04,  1.0914e-04, -1.5053e-04,  1.1997e-04,\n",
       "          1.9550e-05,  3.5804e-05,  1.4764e-05,  7.8568e-05,  6.2382e-05,\n",
       "         -2.3343e-04,  6.4187e-06],\n",
       "        [ 1.1552e-04, -3.7821e-04, -1.7516e-05,  1.3714e-04,  1.2858e-04,\n",
       "         -2.6663e-04,  7.8993e-05,  1.3128e-04, -7.0773e-05, -2.5823e-04,\n",
       "          3.7243e-05,  2.5783e-05,  2.7608e-05,  1.6981e-04, -1.8891e-04,\n",
       "         -1.1918e-04,  1.5775e-04,  2.4464e-05, -1.6813e-05, -5.6378e-05,\n",
       "          2.0311e-04,  3.8279e-05,  8.9876e-05, -5.0558e-06,  1.5562e-04,\n",
       "         -9.8408e-05,  1.0972e-04],\n",
       "        [-2.7791e-04, -3.2428e-04,  3.6140e-05,  7.3308e-05, -4.4275e-05,\n",
       "          5.7770e-05,  7.7038e-05,  6.9760e-05,  8.2675e-05, -2.1567e-04,\n",
       "          1.7984e-04,  1.0629e-05, -8.3395e-05,  3.9912e-06,  5.6245e-06,\n",
       "         -1.4988e-04,  4.8985e-05,  1.1753e-04,  7.4657e-05,  7.2121e-05,\n",
       "          6.0460e-05,  3.3022e-05,  7.3258e-05,  1.6480e-04, -8.1394e-05,\n",
       "         -9.1224e-05,  7.3352e-05],\n",
       "        [-4.5605e-05, -4.5477e-05,  5.8202e-05, -4.0523e-05, -4.6046e-05,\n",
       "         -1.2084e-04,  1.5561e-04,  1.8547e-04,  1.8257e-04, -1.6147e-04,\n",
       "          5.5574e-05, -6.8973e-05, -4.7404e-05, -1.9039e-04, -4.5809e-05,\n",
       "         -1.2275e-04,  1.8403e-04,  8.8163e-05, -9.2475e-05, -8.9795e-05,\n",
       "          6.5990e-05, -1.5031e-06, -1.3182e-04,  2.3033e-04,  8.3971e-05,\n",
       "          1.7614e-04, -2.1397e-05],\n",
       "        [-1.0840e-04, -1.0078e-04,  2.1606e-05, -2.3737e-05,  7.1299e-05,\n",
       "         -2.6414e-04,  4.3477e-05,  1.0538e-04, -3.2429e-05, -1.2978e-04,\n",
       "          3.6982e-05,  8.2524e-05, -2.9177e-04,  1.4566e-06,  7.1461e-05,\n",
       "         -1.1044e-04,  1.2651e-04,  1.0471e-04,  7.6160e-05,  1.1714e-04,\n",
       "          1.3518e-04, -5.8005e-05,  1.0865e-04,  2.1233e-04,  1.8119e-04,\n",
       "         -2.6050e-04,  4.1841e-05]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gradient descent\n",
    "for k in range(25):\n",
    "  \n",
    "  # forward pass #softmax function\n",
    "    xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
    "    print(loss.item())\n",
    "  \n",
    "  # backward pass\n",
    "    W.grad = None # set to zero the gradient\n",
    "    loss.backward()\n",
    "  \n",
    "  # update\n",
    "    W.data += -50 * W.grad\n",
    "W.grad  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e008e840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['j', 'u', 'n', 'i', 'd', 'e', '.']\n",
      "junide.\n",
      "['j', 'a', 'n', 'a', 's', 'a', 'h', '.']\n",
      "janasah.\n",
      "['p', 'x', 'z', 'f', 'a', 'y', '.']\n",
      "pxzfay.\n",
      "['a', '.']\n",
      "a.\n",
      "['n', 'n', '.']\n",
      "nn.\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the 'neural net' model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "  \n",
    "  out = []\n",
    "  ix = 0\n",
    "  while True:\n",
    "    # BEFORE:\n",
    "    # p = P[ix]\n",
    "    # NOW:\n",
    "    xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    # ----------\n",
    "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "    if ix == 0:\n",
    "      break\n",
    "  print(out)\n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0435efc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a427e41c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
